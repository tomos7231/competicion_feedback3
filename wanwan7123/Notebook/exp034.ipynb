{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663596835941,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"bc5fbb95-ede6-4348-84c2-611523874f6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Sep 19 14:13:54 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"feedback3-Exp034-deberta-v3-large\"\n","    MODEL_PATH = \"microsoft/deberta-v3-large\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"feedback-prize-english-learning\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback3\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 8\n","    n_epochs = 5\n","    max_len = 1024\n","    target_list = [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]\n","    \n","    weight_decay = 0.01\n","    num_cycles=0.5\n","    beta = (0.9, 0.999)\n","    lr = 1e-5\n","    count_change_lr = 2\n","    eval_step = 100\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    \n","    # GPU Optimize Settings\n","    gpu_optimize_config= {\n","        \"gradient_checkpoint\": True\n","    }\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7993,"status":"ok","timestamp":1663596843932,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"Y3qpAE-53Teb","outputId":"f90b75e5-9c22-491c-80cf-13f9354f19ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.7/dist-packages (0.1.7)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003eiterative-stratification) (1.1.0)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003eiterative-stratification) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.10 in /usr/local/lib/python3.7/dist-packages (1.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10) (4.1.1)\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","from sklearn.metrics import mean_squared_error\n","\n","! pip install iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","! pip install torch==1.10\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_multilabelstratifiedkfold(train, target_col, n_splits, seed):\n","    kf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"559M6w8N4j95"},"outputs":[],"source":["# バッチごとにパディング操作を行う\n","class Collate:\n","    def __init__(self, tokenizer, return_label=False):\n","        self.tokenizer = tokenizer\n","        self.return_label = return_label\n","\n","    def __call__(self, batch):\n","        labels =  [label for _, label in batch]\n","        batch = [_batch for _batch, _ in batch]\n","\n","        output = dict()\n","\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(token_id) for token_id in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","\n","        if self.return_label:\n","            labels = torch.tensor([sample for sample in labels], dtype=torch.float)\n","\n","        return output, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NX6HXpH8gWUV"},"outputs":[],"source":["# 文章のバグを治す\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -\u003e Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -\u003e Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -\u003e str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9c3uiSU3mDy"},"outputs":[],"source":["# =====================\n","# Dataset, Model\n","# =====================\n","\n","def processing_features(df):\n","    df['text'] = df['full_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n","    return df\n","\n","# dataset\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.text = df['text'].to_numpy()\n","        self.labels = df[cfg.target_list].to_numpy()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.text[index])\n","        return inputs, self.labels[index]\n","\n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(text,\n","                               add_special_tokens=True,\n","                               max_length=cfg.max_len,\n","                               padding=\"max_length\",\n","                               truncation=True,\n","                               return_offsets_mapping=False)\n","        return inputs\n","\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.gpu_optimize_config = cfg.gpu_optimize_config\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout\": 0.,\n","                \"hidden_dropout_prob\": 0.,\n","                \"attention_dropout\": 0.,\n","                \"attention_probs_dropout_prob\": 0,\n","            }\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        self.pool = MeanPooling()\n","\n","        # Gradient Checkpointing\n","        if self.gpu_optimize_config['gradient_checkpoint']:\n","            self.backbone.gradient_checkpointing_enable()  \n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.backbone(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs, labels):\n","        # batch, hidden_size\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        if labels is not None:\n","            loss_fct = nn.SmoothL1Loss(reduction='mean')\n","            loss = loss_fct(output, labels)\n","            return loss, output\n","        else:\n","            return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CuPiR3hOlMMY"},"outputs":[],"source":["# def metric\n","def mcrmse(cfg, preds, df):\n","    all_score = 0\n","    for i, column in enumerate(cfg.target_list):\n","        score = np.sqrt(mean_squared_error(preds[:, i], df[column]))\n","        all_score += score/len(cfg.target_list)\n","    return all_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zYWEkSgxKQ-"},"outputs":[],"source":["def get_optimizer_grouped_parameters(cfg, model):\n","    model_type = 'backbone'\n","    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'fc' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": cfg.lr,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n","    layers.reverse()\n","\n","    # 元々のlr\n","    lr = cfg.lr\n","\n","    # グループ分ける用の変数\n","    count = 0\n","    for layer in layers:\n","\n","        # +1していって、余り0になるごとにlrを減衰させる\n","        count += 1\n","        if count % cfg.count_change_lr == 0:\n","            lr *= 0.90\n","\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","\n","    return optimizer_grouped_parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8mhSGk5zSsh"},"outputs":[],"source":["# FGM\n","# https://www.kaggle.com/competitions/tweet-sentiment-extraction/discussion/143764#809408\n","\n","class FGM():\n","    def __init__(self, model):\n","        self.model = model\n","        self.backup = {}\n","\n","    def attack(self, epsilon=0.3, emb_name='word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                self.backup[name] = param.data.clone()\n","                norm = torch.norm(param.grad)\n","                if norm != 0:\n","                    r_at = epsilon * param.grad / norm\n","                    param.data.add_(r_at)\n","\n","    def restore(self, emb_name='word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                assert name in self.backup\n","                param.data = self.backup[name]\n","            self.backup = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def evaluating(cfg, valid_loader, model, criterion, valid_df, fold, best_val_preds, best_val_score):\n","    val_preds = []\n","    val_losses = []\n","    val_nums = []\n","    model.eval()\n","    with torch.no_grad():\n","        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","            for (inputs, labels) in pbar:\n","                for k, v in inputs.items():\n","                    inputs[k] = v.to(cfg.device)\n","                labels = labels.to(cfg.device)\n","                with autocast():\n","                    loss, output = model(inputs, labels)\n","                \n","                output = output.detach().cpu().numpy()\n","                val_preds.append(output)\n","                val_losses.append(loss.item() * len(labels))\n","                val_nums.append(len(labels))\n","                pbar.set_postfix({\n","                    'val_loss': loss.item()\n","                })\n","\n","    val_preds = np.concatenate(val_preds)\n","    val_loss = sum(val_losses) / sum(val_nums)\n","    score = mcrmse(cfg, val_preds, valid_df)\n","\n","    val_log = {\n","        'val_loss': val_loss,\n","        'mcrmse': score\n","    }\n","    display(val_log)\n","\n","    if best_val_score \u003e score:\n","        print('\\033[31m'+'save model weight'+'\\033[0m')\n","        best_val_preds = val_preds\n","        best_val_score = score\n","        torch.save(\n","            model.state_dict(), \n","            os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","        )\n","    \n","    return best_val_preds, best_val_score\n","\n","def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros((len(train), 6), dtype=np.float32)\n","    fold_score = []\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # Datasetの設定\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","\n","        # model\n","        model = CustomModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        optimizer_grouped_parameters = get_optimizer_grouped_parameters(cfg, model)\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","\n","        # enable FGM\n","        fgm = FGM(model)\n","\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps,\n","            num_cycles=cfg.num_cycles\n","        )\n","\n","        # model-training\n","        criterion = nn.MSELoss()\n","        best_val_preds = None\n","        best_val_score = 9999\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            train_losses = []\n","            train_nums = []\n","            model.train() \n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        loss, output = model(inputs, labels)\n","\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","                    train_losses.append(loss.item() * len(labels))\n","                    train_nums.append(len(labels))\n","\n","                    if cfg.gradient_accumulation_steps \u003e 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","\n","                    # FGM attack\n","                    fgm.attack()\n","                    with autocast():\n","                        loss_adv, _ = model(inputs, labels)\n","                    scaler.scale(loss_adv).backward()\n","                    fgm.restore()\n","\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                        \n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","                    if step % cfg.eval_step == 0 and step != 0:\n","                        print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n","                        best_val_preds, best_val_score = evaluating(\n","                            cfg, valid_loader,\n","                            model,\n","                            criterion,\n","                            valid_df,\n","                            fold,\n","                            best_val_preds,\n","                            best_val_score\n","                        )\n","                        model.train()\n","\n","            train_loss = sum(train_losses)/sum(train_nums)\n","            train_log = {\n","                'train_loss':train_loss\n","            }\n","            display(train_log)\n","\n","            # evaluating(epoch)\n","            print(f'fold: {fold}, epoch: {epoch}, complete')\n","            best_val_preds, best_val_score = evaluating(\n","                cfg, valid_loader,\n","                model,\n","                criterion,\n","                valid_df,\n","                fold,\n","                best_val_preds,\n","                best_val_score\n","            )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        fold_score.append(best_val_score)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    score = mcrmse(cfg, oof_pred, train)\n","    print('fold score：', fold_score)\n","    print('CV:', round(score, 4))\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"gSrrvDWVpxN_"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.53)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.12.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.8.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.16.2) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2022.6.15)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.11.6 in /usr/local/lib/python3.7/dist-packages (0.11.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,\u003e=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.97)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers[sentencepiece]) (3.8.1)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf-\u003etransformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (7.1.2)\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e07e4da5a0f74624be96a7b96c7d33cb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f33a94e0c724765a6e402d508086a93","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.13219830961635962, 'mcrmse': 0.5161019809075784}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f6a0982601946fb89805a417b7a7b24","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10958622125408533, 'mcrmse': 0.46878861648768577}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"248eebc314c94deebee674fed7f18db5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11009804226096025, 'mcrmse': 0.46987501413225574}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.22607108083603633}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"578fc2a52053432ba6bedf7254505f86","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10869620723263992, 'mcrmse': 0.46747813702427965}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21b1e4d244804e688b66a88d56d18224","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f8ff01e16ef490d9bd09cedfccbb2d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10772704824690929, 'mcrmse': 0.46503139665007714}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"793613e1755f46ac83dee6e16a1c6667","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10372941876235216, 'mcrmse': 0.4560941773816371}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d547cf7aec54282a6b816b80d0258ac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10020004925520523, 'mcrmse': 0.4481177311185048}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.10356706577112608}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60a27d564f1249ad92e8b4bbdad2a0bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10772952677496254, 'mcrmse': 0.4648289772252716}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0b6433ef7e444eb98145039a5ec4d91","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d10643742d7340428f376a56f2e86d45","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1010954798677998, 'mcrmse': 0.4500897798943335}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"987bcb34b8064f0c88d4436a26caf000","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10828659614867261, 'mcrmse': 0.4661059075278777}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be24d34f6ddf43f984e5d5162bf684ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10285501206851067, 'mcrmse': 0.4538705459443368}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.09077122393052292}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38f773cc2eb247819d2cfeda57819ccf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10150529314642368, 'mcrmse': 0.45083793739987843}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69c4f5b543504a23bc120e8a58b2c0be","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57fd90cd48974f94a3d2afce38575965","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10201993744696497, 'mcrmse': 0.45225524822871715}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"007fb75c80f34a2a9f5d6ebceb2b1f92","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10507423373515648, 'mcrmse': 0.4586856746747196}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc21e9c7671c4846adcd310af4841fc1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.09979562388966455, 'mcrmse': 0.44707003473943785}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.08051431558244979}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"baf157039b3145b59e2238331efde619","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.09937239809871634, 'mcrmse': 0.4460705685427404}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"467dc3d82ba744eea4e97f1ce8db4979","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8542d119a5de4755be9ad0ce16c1bb85","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.09967895240887352, 'mcrmse': 0.4467793460957283}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe88aab92b1c4d9594d373d34f6207f3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10085286051416031, 'mcrmse': 0.44941245922318385}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c98268a91f4246f79731d1133fadf545","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.09984236016221669, 'mcrmse': 0.44712367257665053}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.07342695823067899}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3c311a1455c4a0d81095c06192c699e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.09986623631947486, 'mcrmse': 0.44718237191746896}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7a5804e41fd4533a9d6422c6d4efa40","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5116cf78795d4b5b8a0ef30955795175","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.15165803453017926, 'mcrmse': 0.55357794482618}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94a1b144f03945b59f45d0ea356a4ff3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.13220341056395005, 'mcrmse': 0.5154015835131247}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8988d78064674b97a0e751d08e23b37a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11107092138527301, 'mcrmse': 0.4729010824430304}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.2240539082728536}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9e594756a284fdf853399fd794ea6bc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11575616247200265, 'mcrmse': 0.48317640390710265}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"381bab14b0774dbea22cb1e64bcfa20f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58598841b8224b389ebe408d938c2119","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1046510506064499, 'mcrmse': 0.4582484626650705}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7097c6e1730248079bd41f883a44890b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11313236860670196, 'mcrmse': 0.4764689475770396}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7483d5dbfeb048148f76355806b65789","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1039099942507415, 'mcrmse': 0.45665170012557554}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.10168676357478132}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66c394d28c7346f28069634da6156b32","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12092661018344178, 'mcrmse': 0.49360138713437796}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a55452a7c1f24f54997bfb8c00caa081","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5be0fa64e538443daec5c3a3beb000f9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1090930317401277, 'mcrmse': 0.46790950415866395}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b44858cd8ccd4deab96466e18205a8dd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10526609212388481, 'mcrmse': 0.4596762383102996}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06d79a212b9c4ad6af63f57e4ee8f336","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11408508882059752, 'mcrmse': 0.4784913797129836}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.08959313711661207}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d9d3d51e22445258822c14bc74e0192","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10857408017034274, 'mcrmse': 0.4668708896549744}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecb1758415a244e3aeffd7b302c7bc36","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1d3bdba1c6742a99676b2fcda73753c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10227376978135505, 'mcrmse': 0.4528223036299175}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aee780ac12634800851daf6efcbc6874","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10265527327817367, 'mcrmse': 0.45380836764484744}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12774e1981794416a03061e75d96386b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10223489580140717, 'mcrmse': 0.45297114583855075}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.07698225975036621}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"005a11f107bf416dadb96cf8f76925c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10324340683823192, 'mcrmse': 0.4553407605277934}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcac2dd7d7c74471b9ccb435024a2ab0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1594760f8b3a4ff4b7612a8b38330d80","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10217886894827145, 'mcrmse': 0.45284803938513646}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78435ba4cd554ec2b6c735c8eb5bfc62","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10251170210302409, 'mcrmse': 0.4535530499918151}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"332c24c53c7c4e13818129fb047e2a02","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1023297050009133, 'mcrmse': 0.45314680265109014}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.0692808946970936}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccf53ed99d23439baebbe47415af995a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10230150123246937, 'mcrmse': 0.45309215398168673}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53b12e64ae9546c4be3340e3df164a33","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38db5ca6ae7e4fdb8c9349005bb9f71b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12169735339444007, 'mcrmse': 0.49474599710411155}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e11563293957495f9ae33f5e4b4c1fb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11473444098478083, 'mcrmse': 0.48073742019301036}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c8e7aef566b41afbcdd24e2566a8170","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1152955896371161, 'mcrmse': 0.481665170526521}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.23578038070436633}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf53e0dafc7a44faac8b76912410e122","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1139784201674754, 'mcrmse': 0.47868730075042243}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a593b50b72304ed681c72fe4e354b16d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a141a8b2aeb4d5998d85a4ab13810d1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10870401624142362, 'mcrmse': 0.467153501439826}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a55d58dac97b4bc2bd8a10d114e1c8c9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.111287617126999, 'mcrmse': 0.4728234426264143}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86254b6e477442eaa716d5183b1e873d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1076209138878776, 'mcrmse': 0.46462169645674767}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.10344668108102915}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11b70a6d1a114cc8b195419851ee8454","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10758201730297044, 'mcrmse': 0.46425765613788184}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5aaae4da6cf342d8a63f9e955b617bb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9ce7e68b26c4e4293502b53cb5acd59","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11598702354351882, 'mcrmse': 0.48307413162179397}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09df54fe53924bbe957a4b446c4d6475","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10912887666307752, 'mcrmse': 0.46806098254998363}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1529685165114d6f85c301f45e034e1f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10936276826178631, 'mcrmse': 0.46837468424505024}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.09135784579398078}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ff9e2a62d794dbf9e70de18d813de6a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10361644008275493, 'mcrmse': 0.455947975752575}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"392c753a191143cdbbb09a940329232c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5e517b5793e4d41b2d38bb7fe716455","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10506717868320778, 'mcrmse': 0.4590297767905359}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5422a083ddf4d839b60be343fa8d596","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10406699191655039, 'mcrmse': 0.4569441929426603}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c55dcdc448bf4bddb9613cf10091e59d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10533053206894404, 'mcrmse': 0.4597122381333696}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.07921238272162655}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c66af3eb4bd64bcbad09193f6746f0c6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10385214762233408, 'mcrmse': 0.45633250585407303}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4a87fbc694746aa9fece040681447fd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e73cbbb7eae1424590b22683a6a6852a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10447086647267231, 'mcrmse': 0.45767747176852785}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfb85b26a1f7448fa6b5c3454c4acd74","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10466870410210641, 'mcrmse': 0.45817069886690676}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2609bf75508b477babc713cec4dfa2f7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10467941047209303, 'mcrmse': 0.45819323231681475}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.07149991371175822}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e79fbb945ee4e7d8825220b277ac5de","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10469812495857858, 'mcrmse': 0.4582220444248211}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad4a1c381ccf4b10ae224e0cdfb49c4e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a69fb56ba4f4a87bd0fd4ac08e32df2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12224071044141374, 'mcrmse': 0.4955320022547603}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f7c109b058f4e9195a5b90e9c408d48","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1131663355414215, 'mcrmse': 0.4765163913226854}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e38c3adfec94d7da7ca75a3d4d52b9b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10950171777888028, 'mcrmse': 0.4688210919198821}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.21380533481879002}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6942e57cc41f43e5b1c7e46cc175e08f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11121553384586978, 'mcrmse': 0.4724173808816324}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ea697ac066c452ca8b173cccf76e323","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc752f7867c94f3f99baad239a74229d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11389531197069246, 'mcrmse': 0.4780467834044197}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2b6359b7e3a4723bd7ed404e17f9f6c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10773202935066979, 'mcrmse': 0.4646909480613088}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df94788dd88b481ea7a9150c0ed08445","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10449078715289645, 'mcrmse': 0.4574420789434731}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.10256510804338223}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90d83b7dea7d49709a8570f1dec151ba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1038278180658055, 'mcrmse': 0.45609739128005117}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"626ba1981ae141319f108046d9830840","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29e4c27f72834fd899c262479a99483a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10649331626684769, 'mcrmse': 0.4618404366330053}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76b8b01914b5487d9f6eb3fed1c8bf0d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1216414747068949, 'mcrmse': 0.4941222852361681}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3437d2e7775417095365c9568127095","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10185621829365221, 'mcrmse': 0.4518498384945321}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.09140033676000812}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e3b13f11504498d84cb12b9db522b1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10348058444307283, 'mcrmse': 0.4552896566487054}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"275b780f1332445ba7c0abbe6e8361a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ddaf0893e7c7466b85920b0124fdb693","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10421817603013704, 'mcrmse': 0.45700289290848156}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1611b651bf1943d09418579485da0eb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10202690274895304, 'mcrmse': 0.4520051703885523}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ddd12abfce9b4b35849ebe1c3b44e247","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10150633771401232, 'mcrmse': 0.45090033214477965}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.08056955443947669}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96f57f0304994c07bb4541248fc45abb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10115909351564734, 'mcrmse': 0.4501524202233901}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02e5326fa1384c9cb7e1efe280fec12c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4268794a9e494d568c5a8390ddaafce0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10122622461879954, 'mcrmse': 0.45030048382542825}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2ad0a554ea24fa5a134153abedd8656","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10122201363067798, 'mcrmse': 0.4502585333954477}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7148fae68c64da89f8903213755d91c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10111911793041717, 'mcrmse': 0.450039118043821}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.0741367078460086}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"850e897a9f574b8ea5ce8769265a6394","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10113412315202186, 'mcrmse': 0.4500794044597145}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38c7dc9e0a264c09a74f9a72132ad53b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12ee5d8dcfe545f08d0f2af24e513beb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1246198506077842, 'mcrmse': 0.5022446043034763}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f48fcf49a1ce46a0ab9683250993b728","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.13461198469104668, 'mcrmse': 0.5199042475517179}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"822a3b96ffd54e71a97af8e3e093de2a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11283670325794488, 'mcrmse': 0.4765944704980912}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.23794212422864822}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2750140fecb423fbc5e524dfff38548","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10923929360059216, 'mcrmse': 0.46852216627881527}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d646455079484ef0baec86a6bb730ab5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12e35179b94e4d50bf1722fa0f46c969","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11045505258890674, 'mcrmse': 0.47076434881074725}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"478d21090c6147a98919f89f7e488f43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11148370474653171, 'mcrmse': 0.47286957274056796}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c0a647eeeb648edba8a7d8f4d970847","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1076622334930598, 'mcrmse': 0.4644556348109122}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.1038691863284239}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a3236f20789486c8b89e58a6f779d7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10845459138264742, 'mcrmse': 0.4663561548177904}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb1b5cbd2e434d35b70f398f6c44ca40","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"faf853b156164465ac9897b4f5ef2985","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10431614527693185, 'mcrmse': 0.45811374237799396}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2b701bbbc5848a9a3483ac53af769d7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10147976903887966, 'mcrmse': 0.4515071335072479}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4badf174c7fe4675bf76aca1b399d7fb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.101055799199797, 'mcrmse': 0.45028223161131425}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.09387055739684178}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c5fbfedc4154b0b9cde25901aeb4fb0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10059212613136262, 'mcrmse': 0.44929860232069385}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92ce369bc26746cdba6a94f81e0dc9e3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22117fb2386a416c86371b68f66957b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10137835552777781, 'mcrmse': 0.4511262270331666}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97685542e0fe457193a7248eb4ee9c14","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10119810406966588, 'mcrmse': 0.45066952832054147}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28b8f99681644fc78cc41dcc7a3beddf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10048414307558323, 'mcrmse': 0.4489815500448954}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.08455634233363145}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"311c43511e23433bac249ec1c8b6bc55","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10044671410261213, 'mcrmse': 0.4490884243260894}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1137e377032947d0a0dad5358ad6b248","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e25f8e61491f4a8798d3f4c049ae1f4b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10032280528789286, 'mcrmse': 0.44878415672132016}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0d215952aaa40e09418c7846c7bc047","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1003209725022316, 'mcrmse': 0.4487357908391114}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24647cbd2fb74ef289fc54aff5324c0c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10037357323919721, 'mcrmse': 0.44883619634106253}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.07894919961309799}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc3ee32a373c436283babb7702f93498","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10041126601226494, 'mcrmse': 0.4489150773570745}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold score： [0.4460705685427404, 0.4528223036299175, 0.455947975752575, 0.450039118043821, 0.4487357908391114]\n","CV: 0.4508\n","Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8.09G/8.09G [03:46\u003c00:00, 38.3MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (8GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:01\u003c00:00, 5.43kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 180k/180k [00:03\u003c00:00, 49.9kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (180KB)\n","Starting upload for file tokenizer.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.36M/2.36M [00:03\u003c00:00, 667kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: tokenizer.tar (2MB)\n","Starting upload for file modelconfig.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.42k/2.42k [00:01\u003c00:00, 1.35kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: modelconfig.pth (2KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train_folds.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","train = processing_features(train)\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","cfg.folds = get_multilabelstratifiedkfold(train, cfg.target_list, cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PwTIVNWuwErN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN++prMislqXVvpgfPRwc4h","background_execution":"on","collapsed_sections":[],"mount_file_id":"16c_PSkctEMBMLSiJBt5lcUyW8HaWheaJ","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0f33cb6010d54af4bc3b7c4a8cdef551":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f37f27fe187465fa5caa2b8724e13ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"107981d78111483cbdb9bf1ff841158a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_219b7a8bb0e240fb8be681c5f24fa512","placeholder":"​","style":"IPY_MODEL_39b289742b68492d93b6b03c590aee8a","value":" 105/391 [08:07\u0026lt;42:36,  8.94s/it, loss=0.12, lr=9.95e-6]"}},"1f33a94e0c724765a6e402d508086a93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b03a0b869f784d43a3c6f5008e0a9586","IPY_MODEL_96bfee74842b43069cbf44e2c6854273","IPY_MODEL_a4acd62024c94ede93301de5c45291cb"],"layout":"IPY_MODEL_0f33cb6010d54af4bc3b7c4a8cdef551"}},"20fcf4d702444620b94d0303c200319f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"219b7a8bb0e240fb8be681c5f24fa512":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3975260d10164f3ba32e6705d5cd5db5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39aceeafaee04935a909d5ced30c3c56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39b289742b68492d93b6b03c590aee8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3aeaac0fcfe64dd9b4700e0009f2165d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_afb053ac5bea42718affc1c7e29271ca","max":98,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4b1c9dfe27f4636be26f0c1f4d44673","value":28}},"50f040cd5f8d4e17a39e49db685e9c0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5595d72d1b244d16a34d83901790d1ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58d7c05189d5405fa980efd4985db786":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b9b255f37ab4de6826986403819b73c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"763611e4ec454251874d720056c2bba5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c451b93a41f4461992f10f1b2cb5fc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96bfee74842b43069cbf44e2c6854273":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b9b255f37ab4de6826986403819b73c","max":98,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50f040cd5f8d4e17a39e49db685e9c0e","value":98}},"9835fcd570294c998b5e49386755242b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c54ba1f9eb04ef88685d0f6e7b7ee8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a17140030735426b9776bae10df334ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f37f27fe187465fa5caa2b8724e13ec","max":391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1e32eb1994d433aa29bca7e9fc7b5b7","value":105}},"a4acd62024c94ede93301de5c45291cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7c221e0663d4bbdafb0d6ab483f9e03","placeholder":"​","style":"IPY_MODEL_3975260d10164f3ba32e6705d5cd5db5","value":" 98/98 [01:01\u0026lt;00:00,  1.70it/s, val_loss=0.0834]"}},"afb053ac5bea42718affc1c7e29271ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b03a0b869f784d43a3c6f5008e0a9586":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c54ba1f9eb04ef88685d0f6e7b7ee8b","placeholder":"​","style":"IPY_MODEL_9835fcd570294c998b5e49386755242b","value":"100%"}},"c2c707d96a494d31b8d6cd7154576048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_763611e4ec454251874d720056c2bba5","placeholder":"​","style":"IPY_MODEL_7c451b93a41f4461992f10f1b2cb5fc5","value":" 28/98 [00:17\u0026lt;00:44,  1.58it/s, val_loss=0.103]"}},"c4b1c9dfe27f4636be26f0c1f4d44673":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf39b7a3f8e04dcbb36be52b0c493a30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1e32eb1994d433aa29bca7e9fc7b5b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7c221e0663d4bbdafb0d6ab483f9e03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e07e4da5a0f74624be96a7b96c7d33cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1679d4564674a6da455eb43c4b52823","IPY_MODEL_a17140030735426b9776bae10df334ce","IPY_MODEL_107981d78111483cbdb9bf1ff841158a"],"layout":"IPY_MODEL_cf39b7a3f8e04dcbb36be52b0c493a30"}},"e1679d4564674a6da455eb43c4b52823":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58d7c05189d5405fa980efd4985db786","placeholder":"​","style":"IPY_MODEL_f03d2ffa780c49c0874e69d56b57357c","value":" 27%"}},"e2750140fecb423fbc5e524dfff38548":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e451bc348a824cf39edc4c7cb2abf982","IPY_MODEL_3aeaac0fcfe64dd9b4700e0009f2165d","IPY_MODEL_c2c707d96a494d31b8d6cd7154576048"],"layout":"IPY_MODEL_20fcf4d702444620b94d0303c200319f"}},"e451bc348a824cf39edc4c7cb2abf982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39aceeafaee04935a909d5ced30c3c56","placeholder":"​","style":"IPY_MODEL_5595d72d1b244d16a34d83901790d1ef","value":" 29%"}},"f03d2ffa780c49c0874e69d56b57357c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}