{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1662818971119,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"f3712fb6-8f0d-47f2-aaba-1df0b5d0dd8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Sep 10 14:09:30 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    46W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662818971120,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"feedback3-Exp020-deberta-v3-base\"\n","    MODEL_PATH = \"microsoft/deberta-v3-base\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"feedback-prize-english-learning\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback3\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 8\n","    n_epochs = 5\n","    max_len = 1024\n","    \n","    weight_decay = 0.01\n","    num_cycles = 0.5\n","    beta = (0.9, 0.999)\n","    lr = 1.5e-5\n","    eval_step = 100\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    \n","    # GPU Optimize Settings\n","    gpu_optimize_config= {\n","        \"gradient_checkpoint\": True\n","    }\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10301,"status":"ok","timestamp":1662818981417,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"Y3qpAE-53Teb","outputId":"13471079-4e66-4e3f-a926-ef7d58553a0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.7/dist-packages (0.1.7)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.7.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.21.6)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003eiterative-stratification) (1.1.0)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003eiterative-stratification) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.10 in /usr/local/lib/python3.7/dist-packages (1.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10) (4.1.1)\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","from sklearn.metrics import mean_squared_error\n","\n","! pip install iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","! pip install torch==1.10\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":543,"status":"ok","timestamp":1662818981953,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1662818981953,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_multilabelstratifiedkfold(train, target_col, n_splits, seed):\n","    kf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1662818981953,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"559M6w8N4j95"},"outputs":[],"source":["# バッチごとにパディング操作を行う\n","class Collate:\n","    def __init__(self, tokenizer, return_label=False):\n","        self.tokenizer = tokenizer\n","        self.return_label = return_label\n","\n","    def __call__(self, batch):\n","        labels =  [label for _, label in batch]\n","        batch = [_batch for _batch, _ in batch]\n","\n","        output = dict()\n","\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(token_id) for token_id in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","\n","        if self.return_label:\n","            labels = torch.tensor([sample for sample in labels], dtype=torch.float)\n","\n","        return output, labels"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1662818981953,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"NX6HXpH8gWUV"},"outputs":[],"source":["# 文章のバグを治す\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -\u003e Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -\u003e Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -\u003e str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1662818981953,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"N9c3uiSU3mDy"},"outputs":[],"source":["# =====================\n","# Dataset, Model\n","# =====================\n","\n","def processing_features(df):\n","    df['text'] = df['full_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n","    return df\n","\n","# dataset\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.text = df['text'].to_numpy()\n","        self.labels = df[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].to_numpy()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.text[index])\n","        label = torch.tensor(self.labels[index], dtype=torch.float)\n","        return inputs, self.labels[index]\n","\n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(text,\n","                               add_special_tokens=True,\n","                               max_length=cfg.max_len,\n","                               padding=\"max_length\",\n","                               truncation=True,\n","                               return_offsets_mapping=False)\n","        return inputs\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.gpu_optimize_config = cfg.gpu_optimize_config\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout\": 0.,\n","                \"hidden_dropout_prob\": 0.,\n","                \"attention_dropout\": 0.,\n","                \"attention_probs_dropout_prob\": 0,\n","            }\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )\n","        self.fc = nn.Linear(self.config.hidden_size*4, 6)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size*4)\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","\n","        # Gradient Checkpointing\n","        if self.gpu_optimize_config['gradient_checkpoint']:\n","            self.backbone.gradient_checkpointing_enable()  \n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, inputs, labels):\n","        bert_outputs = self.backbone(**inputs)\n","        # 最終4層をconcatenate\n","        cls = torch.cat([bert_outputs[\"hidden_states\"][-1*i][:, 0] for i in range(1, 4+1)], dim=1)\n","        cls = self.layer_norm1(cls)\n","        logits1 = self.fc(self.dropout1(cls))\n","        logits2 = self.fc(self.dropout2(cls))\n","        logits3 = self.fc(self.dropout3(cls))\n","        logits4 = self.fc(self.dropout4(cls))\n","        logits5 = self.fc(self.dropout5(cls))\n","        output = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        if labels is not None:\n","            loss_fct = nn.SmoothL1Loss(reduction='mean')\n","            loss = loss_fct(output, labels)\n","            return loss, output\n","        else:\n","            return output"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1662818981954,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"fPeBFK41drE5"},"outputs":[],"source":["def get_optimizer_grouped_parameters(model):\n","    model_type = 'backbone'\n","    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'regressor' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": cfg.lr,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n","    layers.reverse()\n","    lr = cfg.lr\n","    for layer in layers:\n","        lr *= 0.95\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","    return optimizer_grouped_parameters"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1662818981954,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"CuPiR3hOlMMY"},"outputs":[],"source":["# def metric\n","def mcrmse(preds, df):\n","    score0 = np.sqrt(mean_squared_error(preds[:, 0], df['cohesion']))\n","    score1 = np.sqrt(mean_squared_error(preds[:, 1], df['syntax']))\n","    score2 = np.sqrt(mean_squared_error(preds[:, 2], df['vocabulary']))\n","    score3 = np.sqrt(mean_squared_error(preds[:, 3], df['phraseology']))\n","    score4 = np.sqrt(mean_squared_error(preds[:, 4], df['grammar']))\n","    score5 = np.sqrt(mean_squared_error(preds[:, 5], df['conventions']))\n","    return (score0 + score1 + score2 + score3 + score4 + score5)/6"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662818981954,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def evaluating(cfg, valid_loader, model, criterion, valid_df, fold, best_val_preds, best_val_score):\n","    val_preds = []\n","    val_losses = []\n","    val_nums = []\n","    model.eval()\n","    with torch.no_grad():\n","        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","            for (inputs, labels) in pbar:\n","                for k, v in inputs.items():\n","                    inputs[k] = v.to(cfg.device)\n","                labels = labels.to(cfg.device)\n","                with autocast():\n","                    loss, output = model(inputs, labels)\n","                \n","                output = output.detach().cpu().numpy()\n","                val_preds.append(output)\n","                val_losses.append(loss.item() * len(labels))\n","                val_nums.append(len(labels))\n","                pbar.set_postfix({\n","                    'val_loss': loss.item()\n","                })\n","\n","    val_preds = np.concatenate(val_preds)\n","    val_loss = sum(val_losses) / sum(val_nums)\n","    score = mcrmse(val_preds, valid_df)\n","\n","    val_log = {\n","        'val_loss': val_loss,\n","        'mcrmse': score\n","    }\n","    display(val_log)\n","\n","    if best_val_score \u003e score:\n","        print('\\033[31m'+'save model weight'+'\\033[0m')\n","        best_val_preds = val_preds\n","        best_val_score = score\n","        torch.save(\n","            model.state_dict(), \n","            os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","        )\n","    \n","    return best_val_preds, best_val_score\n","\n","def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros((len(train), 6), dtype=np.float32)\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # Datasetの設定\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","\n","        # model\n","        model = CustomModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        optimizer_grouped_parameters = get_optimizer_grouped_parameters(model)\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps,\n","            num_cycles=cfg.num_cycles\n","        )\n","\n","        # model-training\n","        criterion = nn.SmoothL1Loss(reduction='mean')\n","        best_val_preds = None\n","        best_val_score = 9999\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            train_losses = []\n","            train_nums = []\n","            model.train() \n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        loss, output = model(inputs, labels)\n","\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","                    train_losses.append(loss.item() * len(labels))\n","                    train_nums.append(len(labels))\n","\n","                    if cfg.gradient_accumulation_steps \u003e 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","                    if step % cfg.eval_step == 0 and step != 0:\n","                        print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n","                        best_val_preds, best_val_score = evaluating(\n","                            cfg, valid_loader,\n","                            model,\n","                            criterion,\n","                            valid_df,\n","                            fold,\n","                            best_val_preds,\n","                            best_val_score\n","                        )\n","                        model.train()\n","\n","            train_loss = sum(train_losses)/sum(train_nums)\n","            train_log = {\n","                'train_loss':train_loss\n","            }\n","            display(train_log)\n","\n","            # evaluating(epoch)\n","            print(f'fold: {fold}, epoch: {epoch}, complete')\n","            best_val_preds, best_val_score = evaluating(\n","                cfg, valid_loader,\n","                model,\n","                criterion,\n","                valid_df,\n","                fold,\n","                best_val_preds,\n","                best_val_score\n","            )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    score = mcrmse(oof_pred, train)\n","    print('CV:', round(score, 4))\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"gSrrvDWVpxN_"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.12.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.53)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.8.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.16.2) (3.8.1)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2022.6.15)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.11.6 in /usr/local/lib/python3.7/dist-packages (0.11.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: sentencepiece!=0.1.92,\u003e=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.97)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers[sentencepiece]) (3.8.1)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf-\u003etransformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (7.1.2)\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d56ade6223db477ea3b155bd8a5e3bde","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"424cd4971b834aa1a80f6de20f9fa8b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11650378485698529, 'mcrmse': 0.4839150463230176}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb88bfd50401407c8a8a1888fa86b110","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12161806654518523, 'mcrmse': 0.4950333318421605}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4bfbeef1da74418a34ffff2682b568b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10960423096518992, 'mcrmse': 0.46880204635848505}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.31485171315005367}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a6188c8c90b4394b9dcc5f5075d3a36","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12096812076809461, 'mcrmse': 0.49251421564082926}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed87e1107a9f4272a34afa77946c73b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"573cc1aca17d457da7586fc496ee33c6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1131936846219975, 'mcrmse': 0.47694246103626564}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63db67dbe2dd41879cb5260ff4f42edb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11154666200013416, 'mcrmse': 0.4732161840226894}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b507131bd26424db945b97c00e9d49d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10774441381625811, 'mcrmse': 0.4640202078561104}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.15027591052567563}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01e162a157074eea8ba8553014f5d478","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10760329623737604, 'mcrmse': 0.4642950130925103}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d48e5e93fad246de862f1e251de3ba37","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8922d4750d014278990966a19d753da1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10779930723597632, 'mcrmse': 0.4644222557182121}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d57764008a1b4010ba9ff517c326b937","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10885134709003332, 'mcrmse': 0.46698786170499473}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a029df737ac4a9d801824ee7cb40d6b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10527202191636385, 'mcrmse': 0.4593856511110556}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.1348199851601325}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d2f846b1ae24e1abc1b308492872953","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10289159964036454, 'mcrmse': 0.4539263572252456}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"998e486a41e14962a2e33aecf58614cd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40072c2177134b61b34297d1bc00d398","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10424551541161964, 'mcrmse': 0.45690171923958184}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"deacffcdf31d4a0c9410d50d9e8fe6a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11308859052408077, 'mcrmse': 0.47637580453346057}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ec7b4f7b70a4f3f8096dda077e2aeaf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10261793108776097, 'mcrmse': 0.45323121159286034}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.12041705979220092}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ad2660912e84b11a784ba8abcb53269","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10185493608874738, 'mcrmse': 0.45165607416567594}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1764de6df5047f6901fb38517aa77c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e3f59ea645041dca193439b28fb99a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10236787380617293, 'mcrmse': 0.4527805101183818}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35cc828cb5f04319a267b6a458daccac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10169528241809982, 'mcrmse': 0.451262698693387}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01a43801fbb94f9d96a7b1c82ae71099","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10193499730294928, 'mcrmse': 0.45179187292019046}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.11250000012576428}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4001e22c143a447aa2693ace9b4f74b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10164396985031454, 'mcrmse': 0.451141856326909}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"849ed18831a447709504ff011b6ca339","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab069603fdaf40d3adb972ff2dafedc0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12220185530749013, 'mcrmse': 0.49600861603722574}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"390b1f3814024b7aaa973f215c6cd742","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1172437114429352, 'mcrmse': 0.4855703869945544}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"375a67b2c7bb4f7bb0bb40336c0f55c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11314430676809825, 'mcrmse': 0.4769340975646372}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.2832471729849306}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a8635438a01447f80e9c66ddfd1479c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11501474806974674, 'mcrmse': 0.48057172362993}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6eb35729653f4f83b3d4c0a09cf9a502","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f2c317fba354e42907144ad4e1bc9db","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11511214503763888, 'mcrmse': 0.4796160387960857}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12e7dff5c2d740d8a28e190ba7bb8449","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11102163936291008, 'mcrmse': 0.47174850477508384}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98d967315b9d49bea8b15bea6aaeae50","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10836994605160308, 'mcrmse': 0.466057164279917}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.14141795906188237}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca1d692f8f0346b2aa1e1c3da879d718","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11683646482944793, 'mcrmse': 0.4846360073369451}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"376993b95d324c16a4601b0651b51bb4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8042d12739044985af457bc00ce8c00a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11470507131948934, 'mcrmse': 0.47960966786237685}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76a08f6a4a7d452183b24e1b2c0ac73b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10601223164058432, 'mcrmse': 0.4614668439384913}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"941c255c85ae414fb84a9ac36a731e84","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10928008984179637, 'mcrmse': 0.4688862589295603}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.12445607495582317}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f01e2cd39444f4fa109a038bbed62ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.106758298031215, 'mcrmse': 0.4630909643450787}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7944ea06542044e7a0ada418848c3e09","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86e21cc966c14cc98de95007be1905a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10821326862007265, 'mcrmse': 0.4662415300995588}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a307a6c0e694bb3b3aed07b6e51812f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10683141480346292, 'mcrmse': 0.4633507906242485}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c3f686b53aa4a02900dfb7ab8f21105","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1066512237011549, 'mcrmse': 0.46275633041777575}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.11228457864021402}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1277c61dc3b461882e1d79a88bb86b2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10575015394737894, 'mcrmse': 0.46075126797042637}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09b8c882a75a4d18b88562eb1d019020","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecaded53a4b94bbdaf51ccaad4caeba6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10637932532439591, 'mcrmse': 0.4622281341100905}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69e34aa42d9b41299e5131bca35667a2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10606270225416503, 'mcrmse': 0.4613911219750575}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4183f38aa3048bebbd98f8778838ed2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10571302754250218, 'mcrmse': 0.46065814985905607}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.10462406073765987}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c136319e8154c06b1310a9cccfc0bbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10575136738338081, 'mcrmse': 0.4607447649237639}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f4d4fa8a5be440c96ead6a458748722","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93e6947e878c40f7bbdecee0cece73c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1912545107514657, 'mcrmse': 0.6252525658695274}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19400c7a73654c1ca6d3b90d97082da7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1239354210665159, 'mcrmse': 0.49985362683266193}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"856a24d973b446d08f29692221e6dd27","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12166166600897489, 'mcrmse': 0.4948559194644566}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.29282114041202206}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87c5afd154a64eefbf06f57fa737e0f1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.13166381344389733, 'mcrmse': 0.5127847491981755}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f23bd809b3a64c79915af73619c9c877","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d601b9641cc41928f16fa0819b31579","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1205240811990655, 'mcrmse': 0.49240138053553784}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc672667874140dc84eb1e9e3091eeec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12985605151985613, 'mcrmse': 0.510325054927861}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c491cd530ad4949ae7c4142f5c7cb62","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11875378481491143, 'mcrmse': 0.48860790763010997}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.1445219151847198}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0c35e2ecc8a4579b81ad797cfa494d4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11881436249407966, 'mcrmse': 0.4889373205569161}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b38d9825997a43dda06fb25b870f1fb7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58125d41b407466ca0f8285c95aeb964","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10695184490945943, 'mcrmse': 0.4636723888398084}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"540c98575cad4e228b77d04295fbcf79","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11275550547768087, 'mcrmse': 0.47688454797198704}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1affc11782b047ae8888068ca42d06f0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11106275896663251, 'mcrmse': 0.4733279785778401}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.12524620012935164}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"edcd4dcd47584a4181f3bb5f11bc94a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.116504435991997, 'mcrmse': 0.48395399252640486}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48eb30ab752b4f92a04ecd36279c3f0d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc345d6606f14e9495c88e680745a8ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10956308924023757, 'mcrmse': 0.469600302184934}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e08656e53434c88bb0405c92d97bf03","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11096186871113985, 'mcrmse': 0.4728372028577234}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89aa2bf84bce4c3eb02a2f8040d69625","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1098156183996164, 'mcrmse': 0.46988613304489885}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.11288253864859377}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e2b290775db47eda52b673dddb7d046","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10707093714295751, 'mcrmse': 0.46403914242657257}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2cd7126c0d35460a84ed87fb309de6d0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f468c92e55f44de2b94f67a83516613c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10629397295320125, 'mcrmse': 0.462381614805584}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db97424abcf54b1d8bb10e4c2ee1532d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10684750884618906, 'mcrmse': 0.46368734657775224}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"969ad4f12797475ab0831ebfd656f063","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10622828419479872, 'mcrmse': 0.46222165234019935}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.10614209863192894}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"580b7aad262543ea91faa8d985fad909","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10619992576063136, 'mcrmse': 0.4621856520523489}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b993c3961d8a432cb26908ec2ccb6642","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d3c24b96e9744c39484ed63ce273f59","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.15396045184577517, 'mcrmse': 0.5568864895083218}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0715154bdac4389802124b8f190412f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11888061581975054, 'mcrmse': 0.4886384370265618}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8913251494c4815a86037db7a0aaa1b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12813947073486456, 'mcrmse': 0.5077561687663076}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.2859602876941261}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c50c1c1857bc44348fd35dea1b2f6dfa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10839139696810861, 'mcrmse': 0.46607740899465494}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ad3505c4308496f805475c544ddd7e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e5c4ed1f3e94166af88e02321f7f86f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10769413219159826, 'mcrmse': 0.46438781396029793}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97d01bb9afeb4387a9ffe6b51bd1271c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11049870580739682, 'mcrmse': 0.4708564531802388}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f7d94e107f241dda1a9508fc8b3192b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11222437489063233, 'mcrmse': 0.4744652420538466}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.13663188061293433}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a8618b792d94c59a2159d6e61cb2548","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10703879072690559, 'mcrmse': 0.4631192502597156}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7c74458f61f4b499ac11deca361bd48","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b0c63f0a4624e38833cf3aab04fd10d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10532981578422629, 'mcrmse': 0.45943798441499156}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc4ca6733a114f9da54c6d6d45f2e82c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10662090157151527, 'mcrmse': 0.4622939959141597}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81db77670cac4eb1bd8c5a6eba2f551e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12051075807465311, 'mcrmse': 0.4918864703473608}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.1210891117563333}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69bd1f35bb6549009f0610b9dbb57981","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1074586462448625, 'mcrmse': 0.4640841140142213}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1420a50af40e42249b42a002a31c13db","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f8691027b884189a6283486323ebd03","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1043211663013224, 'mcrmse': 0.4571554201953913}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a374d88cc4c9413796ac0dd24697975b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10422753399747717, 'mcrmse': 0.45713142888585323}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90f351c1610d42548c02b6e595f2ad40","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10406400979784748, 'mcrmse': 0.4567595739886559}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.10675182203998042}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fea0de9474c40b1a835bc4a1dcd17de","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10750413367815335, 'mcrmse': 0.4644704440835965}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d734bcf29c6f4d1d8b14749cbe4897b0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ac18f1740644acb84d83dec2b617293","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10299233036577854, 'mcrmse': 0.45432960571968134}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"094bdf33ffed429194c26cd1784fb3fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10345065303127784, 'mcrmse': 0.45530340268350056}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5b682cc255c4ada830b8f8534c08bc3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10311979051593624, 'mcrmse': 0.45458170464150555}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.09962351933655227}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce3cdd158380455db9cdcaf003a20a20","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10309040171982688, 'mcrmse': 0.45451594790385275}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a761dcccb3f41118b1075a20c98bbf4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f099d4f1fe8b42eab2ca1e3393954cb9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.145513339458829, 'mcrmse': 0.5416079561472293}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b4997b750f445159771526d63bb8654","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12546605098506677, 'mcrmse': 0.5034104192560859}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abba9e7ee3d542e581f45079914e85dd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1127342053348451, 'mcrmse': 0.4763503778323222}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.32709896676909284}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df48a4b4296b47d18d987145ca985dd8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1168241670255161, 'mcrmse': 0.4849909720803131}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"638eb68a49c745e0bbc13b143c138e77","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ce05dbe9b874f0fbecd3edf32437bab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.1151013647198982, 'mcrmse': 0.4817078740555634}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c57bee895834714ac68b58cae309588","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.12414013232340289, 'mcrmse': 0.5002285270271848}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce281a8e2b2e4e03b1c4e7815f4074a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11335720809752983, 'mcrmse': 0.47747337655480254}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.15193694119182083}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05acf56c5f4e453a8a9acda0d7c95ad7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10429820972863975, 'mcrmse': 0.45807802012333393}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5dc0ecfec13845f3917d857008e2863b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e342477c86e4cc5ad0faac1731d8290","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11148690270340961, 'mcrmse': 0.47391033700201574}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d90761fe5de94454bdc72de8897c832d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.11504437926861331, 'mcrmse': 0.48211633766025264}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5836e37f56874f9384c1f744d597b67c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.106892963371161, 'mcrmse': 0.46398573379159175}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.13349318551971479}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fd064f1c32d427c8357be20b9818cf5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10908351038270594, 'mcrmse': 0.4686853555346297}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d3ae4c1b7994f50a036e5a0c5cf08f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52e718328cc94ecbb2d90a470103f624","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.106889714746524, 'mcrmse': 0.4639411753443923}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"995acf8c19dc4e3da6c17f50c70ca8a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10406871014238929, 'mcrmse': 0.4575813064542369}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68726d3ea920427980aa5af23ccd0745","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10486955443382873, 'mcrmse': 0.45948033641291525}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.12228809411415968}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"629be630eed142a0bd66b3bd42d7af4e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10423608293847354, 'mcrmse': 0.4579201892646674}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c6257e5c2c646e6808fd4a3f79202c6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 4, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67158508721944389d165c86ecdd7d62","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10334183132785665, 'mcrmse': 0.4559982729581514}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 4, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25d90c7863834145a1aa5165bfa62283","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10364198574172262, 'mcrmse': 0.45658980619191486}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 4, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb03b14e1c1649d2bc3dde331f487f9e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10364613440030676, 'mcrmse': 0.45659274210893797}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.11432163411622767}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 4, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25be60814cc74552af6c1cd6956fc305","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.10358989010076694, 'mcrmse': 0.45647490077777064}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CV: 0.457\n","Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3.43G/3.43G [01:37\u003c00:00, 37.6MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (3GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:01\u003c00:00, 7.21kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 180k/180k [00:02\u003c00:00, 65.0kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (180KB)\n","Starting upload for file tokenizer.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.36M/2.36M [00:02\u003c00:00, 1.18MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: tokenizer.tar (2MB)\n","Starting upload for file modelconfig.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.42k/2.42k [00:01\u003c00:00, 1.27kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: modelconfig.pth (2KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train_folds.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","train = processing_features(train)\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","cfg.folds = get_multilabelstratifiedkfold(train, [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"], cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PwTIVNWuwErN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPamSO0UQyJteulUF7kiWj7","background_execution":"on","collapsed_sections":[],"mount_file_id":"16c_PSkctEMBMLSiJBt5lcUyW8HaWheaJ","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"027d24b71e924165ba569a6185200055":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a62300d2bde4b33ae6e64b22c83dae6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d8c897c04174dd68498bab4a905efa0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b94891dde1a4b84bf81546ddf32511f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2011b196dc4b4fec97c4638202ca9c4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf7e2bc153ac4a9c83f16dc904df44e5","placeholder":"​","style":"IPY_MODEL_207e1b17144b4a0ba01e9ec4031afff5","value":"100%"}},"207e1b17144b4a0ba01e9ec4031afff5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20aa9f4a90514317845ef3e867878101":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b94891dde1a4b84bf81546ddf32511f","placeholder":"​","style":"IPY_MODEL_aaba69a4698b4946be2b31e91299ac40","value":" 98/98 [00:27\u0026lt;00:00,  3.82it/s, val_loss=0.0956]"}},"32ef8f24b45647cc83f4fb6c9f10d1f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"348e20a391594bd7ab739f2f90dc87dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbc4d5caf50b4c6eba13e24e291bf49f","placeholder":"​","style":"IPY_MODEL_0a62300d2bde4b33ae6e64b22c83dae6","value":" 98/98 [00:27\u0026lt;00:00,  3.79it/s, val_loss=0.0882]"}},"34eb8803b61646028e06757ef04d492c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36afd00303594a1cbad684a58175cd00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34eb8803b61646028e06757ef04d492c","placeholder":"​","style":"IPY_MODEL_0d8c897c04174dd68498bab4a905efa0","value":"100%"}},"3973a33c33914badb39690afb4082da4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"424cd4971b834aa1a80f6de20f9fa8b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36afd00303594a1cbad684a58175cd00","IPY_MODEL_635c7abbf8124b03ad5e5f3f309fd70f","IPY_MODEL_20aa9f4a90514317845ef3e867878101"],"layout":"IPY_MODEL_77a3e57dc3d54671987392ace303db78"}},"4f3193bfd9ff47d9b02e508b83cc5917":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fb565a35ff448eaabc8ff10ccb77eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e24f38c81f94428190cfd495073c1777","max":98,"min":0,"orientation":"horizontal","style":"IPY_MODEL_729dfbdc47474994a01e046509c13c4b","value":98}},"6277c3435ab54dd6a0f87b1215c35b1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"635c7abbf8124b03ad5e5f3f309fd70f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd95d916e8aa42589a4e56f41d452436","max":98,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e99a51fdf3bb480a87d08a003b73a032","value":98}},"729dfbdc47474994a01e046509c13c4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"773907d5b22147b58b5cbd4328a8c7f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_027d24b71e924165ba569a6185200055","placeholder":"​","style":"IPY_MODEL_9373c7a3a1e043e2ad58707eda29205b","value":" 91/98 [00:25\u0026lt;00:01,  3.59it/s, val_loss=0.0953]"}},"77a3e57dc3d54671987392ace303db78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c98734403f4a6db86136a2ea214a0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8591230289fa4494b23df39302f54663":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77c98734403f4a6db86136a2ea214a0a","placeholder":"​","style":"IPY_MODEL_d2712ab278024579a19ce3be32912aa6","value":" 93%"}},"894fd6be2a8a4c51bc3bc6d09b169b52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_32ef8f24b45647cc83f4fb6c9f10d1f2","max":391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4953b23af93459d8d1a8ac6406d6eac","value":300}},"91ac696f91654d44accc869c2d7e2a7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"935455495f4743c0992373c351c26c1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a226b9e577fb42e1b88eeb83547fc19c","max":98,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8659a0f547f44779e8927be474b0f68","value":91}},"9373c7a3a1e043e2ad58707eda29205b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c5f4f8541884fe8900533f0b4621e2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9cab7526a1e453a81d98d038d1f87c5","placeholder":"​","style":"IPY_MODEL_be0890dd6d6e4268aa998652cfba2dce","value":" 77%"}},"a226b9e577fb42e1b88eeb83547fc19c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4bfbeef1da74418a34ffff2682b568b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8591230289fa4494b23df39302f54663","IPY_MODEL_935455495f4743c0992373c351c26c1b","IPY_MODEL_773907d5b22147b58b5cbd4328a8c7f3"],"layout":"IPY_MODEL_6277c3435ab54dd6a0f87b1215c35b1b"}},"aaba69a4698b4946be2b31e91299ac40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3c453325a7e45baac20f3e2ecf48acd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9cab7526a1e453a81d98d038d1f87c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e9dfe22f8f42459cf463316f42f4bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3973a33c33914badb39690afb4082da4","placeholder":"​","style":"IPY_MODEL_b3c453325a7e45baac20f3e2ecf48acd","value":" 300/391 [05:00\u0026lt;01:14,  1.22it/s, loss=0.154, lr=1.42e-5]"}},"be0890dd6d6e4268aa998652cfba2dce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf7e2bc153ac4a9c83f16dc904df44e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4953b23af93459d8d1a8ac6406d6eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2712ab278024579a19ce3be32912aa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d56ade6223db477ea3b155bd8a5e3bde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c5f4f8541884fe8900533f0b4621e2e","IPY_MODEL_894fd6be2a8a4c51bc3bc6d09b169b52","IPY_MODEL_b9e9dfe22f8f42459cf463316f42f4bb"],"layout":"IPY_MODEL_4f3193bfd9ff47d9b02e508b83cc5917"}},"d8659a0f547f44779e8927be474b0f68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbc4d5caf50b4c6eba13e24e291bf49f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e24f38c81f94428190cfd495073c1777":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e99a51fdf3bb480a87d08a003b73a032":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb88bfd50401407c8a8a1888fa86b110":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2011b196dc4b4fec97c4638202ca9c4d","IPY_MODEL_5fb565a35ff448eaabc8ff10ccb77eac","IPY_MODEL_348e20a391594bd7ab739f2f90dc87dc"],"layout":"IPY_MODEL_91ac696f91654d44accc869c2d7e2a7c"}},"fd95d916e8aa42589a4e56f41d452436":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}