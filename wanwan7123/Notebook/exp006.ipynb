{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1662171352227,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"96e3f7b6-ea25-48ce-85eb-a6754112fca6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Sep  3 02:15:51 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662171354030,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"feedback3-Exp006-deberta-v3-large\"\n","    MODEL_PATH = \"microsoft/deberta-v3-large\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"feedback-prize-english-learning\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback3\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 8\n","    n_epochs = 4\n","    max_len = 1024\n","    \n","    weight_decay = 0.001\n","    beta = (0.9, 0.999)\n","    lr = 7e-6\n","    eval_step = 100\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    \n","    # GPU Optimize Settings\n","    gpu_optimize_config= {\n","        \"gradient_checkpoint\": True\n","    }\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104401,"status":"ok","timestamp":1662171459769,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"Y3qpAE-53Teb","outputId":"a2c9b6de-505c-4a16-87ca-b58c006af77f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting iterative-stratification\n","  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.21.6)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003eiterative-stratification) (1.1.0)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003eiterative-stratification) (3.1.0)\n","Installing collected packages: iterative-stratification\n","Successfully installed iterative-stratification-0.1.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.10\n","  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:43tcmalloc: large alloc 1147494400 bytes == 0x3939a000 @  0x7f9e70e37615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10) (4.1.1)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.10.0\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","from sklearn.metrics import mean_squared_error\n","\n","! pip install iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","! pip install torch==1.10\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":361,"status":"ok","timestamp":1662171501065,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1662171501404,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_multilabelstratifiedkfold(train, target_col, n_splits, seed):\n","    kf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":348,"status":"ok","timestamp":1662171504818,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"559M6w8N4j95"},"outputs":[],"source":["# バッチごとにパディング操作を行う\n","class Collate:\n","    def __init__(self, tokenizer, return_label=False):\n","        self.tokenizer = tokenizer\n","        self.return_label = return_label\n","\n","    def __call__(self, batch):\n","        labels =  [label for _, label in batch]\n","        batch = [_batch for _batch, _ in batch]\n","\n","        output = dict()\n","\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(token_id) for token_id in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","\n","        if self.return_label:\n","            labels = torch.tensor([sample for sample in labels], dtype=torch.half)\n","\n","        return output, labels"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1662171505457,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"NX6HXpH8gWUV"},"outputs":[],"source":["# 文章のバグを治す\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -\u003e Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -\u003e Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -\u003e str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":528,"status":"ok","timestamp":1662171511680,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"N9c3uiSU3mDy"},"outputs":[],"source":["# =====================\n","# Dataset, Model\n","# =====================\n","\n","def processing_features(df):\n","    df['text'] = df['full_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n","    return df\n","\n","# dataset\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.text = df['text'].to_numpy()\n","        self.labels = df[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].to_numpy()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.text[index])\n","        label = torch.tensor(self.labels[index], dtype=torch.half)\n","        return inputs, self.labels[index]\n","\n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(text,\n","                               add_special_tokens=True,\n","                               max_length=cfg.max_len,\n","                               padding=\"max_length\",\n","                               truncation=True,\n","                               return_offsets_mapping=False)\n","        return inputs\n","\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.gpu_optimize_config = cfg.gpu_optimize_config\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout\": 0.,\n","                \"hidden_dropout_prob\": 0.,\n","                \"attention_dropout\": 0.,\n","                \"attention_probs_dropout_prob\": 0,\n","                \"layer_norm_eps\": 1e-7,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": 6,\n","            }\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self.pool = MeanPooling()\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","\n","        # Gradient Checkpointing\n","        if self.gpu_optimize_config['gradient_checkpoint']:\n","            self.backbone.gradient_checkpointing_enable()  \n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.backbone(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs, labels):\n","        outputs = self.backbone(**inputs)\n","        last_hidden_state = outputs[0]\n","        out = self.layer_norm1(last_hidden_state[:, 0, :])\n","        logits1 = self.fc(self.dropout1(out))\n","        logits2 = self.fc(self.dropout2(out))\n","        logits3 = self.fc(self.dropout3(out))\n","        logits4 = self.fc(self.dropout4(out))\n","        logits5 = self.fc(self.dropout5(out))\n","        output = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        if labels is not None:\n","            loss_fct = nn.MSELoss()\n","            loss = loss_fct(output, labels)\n","            return loss, output\n","        else:\n","            return output"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1662171512116,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"fPeBFK41drE5"},"outputs":[],"source":["def get_optimizer_grouped_parameters(model):\n","    model_type = 'backbone'\n","    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'regressor' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": cfg.lr,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n","    layers.reverse()\n","    lr = cfg.lr\n","    for layer in layers:\n","        lr *= 0.98\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","    return optimizer_grouped_parameters"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1662171512116,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"CuPiR3hOlMMY"},"outputs":[],"source":["# def metric\n","def mcrmse(preds, df):\n","    score0 = np.sqrt(mean_squared_error(preds[:, 0], df['cohesion']))\n","    score1 = np.sqrt(mean_squared_error(preds[:, 1], df['syntax']))\n","    score2 = np.sqrt(mean_squared_error(preds[:, 2], df['vocabulary']))\n","    score3 = np.sqrt(mean_squared_error(preds[:, 3], df['phraseology']))\n","    score4 = np.sqrt(mean_squared_error(preds[:, 4], df['grammar']))\n","    score5 = np.sqrt(mean_squared_error(preds[:, 5], df['conventions']))\n","    return (score0 + score1 + score2 + score3 + score4 + score5)/6"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1662171517937,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def evaluating(cfg, valid_loader, model, criterion, valid_df, fold, best_val_preds, best_val_score):\n","    val_preds = []\n","    val_losses = []\n","    val_nums = []\n","    model.eval()\n","    with torch.no_grad():\n","        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","            for (inputs, labels) in pbar:\n","                for k, v in inputs.items():\n","                    inputs[k] = v.to(cfg.device)\n","                labels = labels.to(cfg.device)\n","                with autocast():\n","                    loss, output = model(inputs, labels)\n","                \n","                output = output.detach().cpu().numpy()\n","                val_preds.append(output)\n","                val_losses.append(loss.item() * len(labels))\n","                val_nums.append(len(labels))\n","                pbar.set_postfix({\n","                    'val_loss': loss.item()\n","                })\n","\n","    val_preds = np.concatenate(val_preds)\n","    val_loss = sum(val_losses) / sum(val_nums)\n","    score = mcrmse(val_preds, valid_df)\n","\n","    val_log = {\n","        'val_loss': val_loss,\n","        'mcrmse': score\n","    }\n","    display(val_log)\n","\n","    if best_val_score \u003e score:\n","        print(\"save model weight\")\n","        best_val_preds = val_preds\n","        best_val_score = score\n","        torch.save(\n","            model.state_dict(), \n","            os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","        )\n","    \n","    return best_val_preds, best_val_score\n","\n","def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros((len(train), 6), dtype=np.float32)\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # Datasetの設定\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","\n","        # model\n","        model = CustomModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        optimizer_grouped_parameters = get_optimizer_grouped_parameters(model)\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","\n","        # model-training\n","        criterion = nn.MSELoss()\n","        best_val_preds = None\n","        best_val_score = 9999\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            train_losses = []\n","            train_nums = []\n","            model.train() \n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        loss, output = model(inputs, labels)\n","\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","                    train_losses.append(loss.item() * len(labels))\n","                    train_nums.append(len(labels))\n","\n","                    if cfg.gradient_accumulation_steps \u003e 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","                    if step % cfg.eval_step == 0 and step != 0:\n","                        print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n","                        best_val_preds, best_val_score = evaluating(\n","                            cfg, valid_loader,\n","                            model,\n","                            criterion,\n","                            valid_df,\n","                            fold,\n","                            best_val_preds,\n","                            best_val_score\n","                        )\n","                        model.train()\n","\n","            train_loss = sum(train_losses)/sum(train_nums)\n","            train_log = {\n","                'train_loss':train_loss\n","            }\n","            display(train_log)\n","\n","            # evaluating(epoch)\n","            print(f'fold: {fold}, epoch: {epoch}, complete')\n","            best_val_preds, best_val_score = evaluating(\n","                cfg, valid_loader,\n","                model,\n","                criterion,\n","                valid_df,\n","                fold,\n","                best_val_preds,\n","                best_val_score\n","            )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    score = mcrmse(oof_pred, train)\n","    print('CV:', round(score, 4))\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gSrrvDWVpxN_"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 15.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,\u003e=0.10.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 59.5 MB/s \n","\u001b[?25hCollecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 84.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.8.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 97.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.16.2) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2022.6.15)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d5dbb006e09fb077d20f5e02ced1225bc44c0dde9fd252a11a5c443da3fa8b5d\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.16.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers==0.11.6\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 16.3 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","Successfully installed tokenizers-0.11.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.9.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Collecting sentencepiece!=0.1.92,\u003e=0.1.91\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 14.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers[sentencepiece]) (3.8.1)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf-\u003etransformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (7.1.2)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccd475efd89445098188981e89b863fd","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47db5e44afa348d6aca42d048f1ea953","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"338dcac74758461283c06cdf752b14e3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aab70e6739dd4310b468f27c731a6717","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46f574a8e6c848d08738f0aa6de9bc17","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c2612fcc56d4318a0d0184dd84c17d7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.33125555682975005, 'mcrmse': 0.5733181569389614}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 0, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e72ade2c21454214b68077f56ecf77ff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23644571943813578, 'mcrmse': 0.48548096082622944}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 0, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2662c624a11439395563e70268e0bae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2259792905786763, 'mcrmse': 0.4749052756512961}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 1.0593881198512318}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0285a115d2044debb950e219cb5535ec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2432544385761861, 'mcrmse': 0.4922206272061}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47331ee0a6c24249820b0220e86d5fb9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d52ac365f974b988f395d036b709d85","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2342975734521056, 'mcrmse': 0.4835174644130462}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c308edb9b9244f3806480f84cede6b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2258871568133459, 'mcrmse': 0.4747150707325745}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 0, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2791cf81cbc44f48a7d8838d2a208a11","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21899709398941616, 'mcrmse': 0.4675027925340057}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.2560483391403847}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a13ba52af974f20961fe61cb6a043e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2201716891868645, 'mcrmse': 0.4688620170062086}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6dd1ab60b2934805b333f882773e2416","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2d5a0554b524afb952857db430cce46","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21690260186372207, 'mcrmse': 0.4651050872927401}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 0, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d313ecb2e97345548cffbb675824cffe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23767533723045797, 'mcrmse': 0.48693287052711604}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92903b59f3dd4641b6f997c2930af852","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21432496786422436, 'mcrmse': 0.46237183486890093}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.22774900835188452}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d049ac4208f43c4aa17ac2fe29ceb3c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20981301237707553, 'mcrmse': 0.45755764758283757}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd0d91f17c4a4b2ca574b1ed2a0965eb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a24f6f479b73419eb31a1ec1dc33f20f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21036291316799496, 'mcrmse': 0.4580164501536836}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3ceccab286b4be28b591ff82fe14fc7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.214538573037328, 'mcrmse': 0.4624109868414952}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd638f4e3a684a94be7e902cd7cd71a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21015867472762037, 'mcrmse': 0.45779660339065115}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.2091174167783364}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"370a62aad0eb4277aaa4bd1865a7ed5c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2133385612226813, 'mcrmse': 0.4612447869235364}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"710e34f2d65240c6ba08491cf04f9ed8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c0113ed53e0475eaeece28e0d0fce92","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2996626004177035, 'mcrmse': 0.5469054341847563}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 1, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"096fdcf5b2374b62912c27d033e5f32c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.24190053260037117, 'mcrmse': 0.4912566194199239}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 1, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4a91cf1d5b14db69d936f24b1404165","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22554649365054846, 'mcrmse': 0.47411411646310175}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.8637558855592747}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"065f1f03a95f4865be06143eed0d7735","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21674230279898127, 'mcrmse': 0.46496804862259505}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ac2099f10fc4978824300220bd05057","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9555491f4b3444c0a6e591cfddcb7aba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22085577032575204, 'mcrmse': 0.4691993872143636}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d692342159b4b3a915cac44346511b8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2159228758793681, 'mcrmse': 0.46405319643141335}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 1, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b1972715fad4dc18b48af9c4b8ca2de","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22278946596239413, 'mcrmse': 0.47122860949129275}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.24496751667364783}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3d9eed3108d41d089f9597e5a448da0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21585318868644393, 'mcrmse': 0.4640006455300653}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b9cc79658b4453688648426db39c716","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6d3160d10a24b96b8adb9bef4e81c5c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2089575878885666, 'mcrmse': 0.4565808925206207}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 1, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b69e9981203644d78254ddeac724e4b8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21469308464463185, 'mcrmse': 0.46260277038806213}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aee7d5ef62f42bda970d6b1c2312ceb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21377707953121167, 'mcrmse': 0.46190419377406866}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.2235874763458891}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02e039857b9a4f2aaccbfb7f884335a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22671649628824353, 'mcrmse': 0.47560465055368656}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25fcc929e41d4976b360522aa0bfa664","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d478c09cbba458b8a5974c8ce064ce1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2110565421986245, 'mcrmse': 0.4587494749147682}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23119abb1981455fa0972a63463744d6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20810249778959486, 'mcrmse': 0.4556760869462484}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 1, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f25f993c2a25404fafd8ea07c35cf25f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.209218411648106, 'mcrmse': 0.4568953180593717}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.20871048900858521}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4710d5e953c442dbdb3f7a98cb518ae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2075971194839112, 'mcrmse': 0.4551053799434122}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05637d6a30e04dcab5d7ea07e320ac0b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd9e7615bf354cf4afca8dfdafd5f91e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2667720483620758, 'mcrmse': 0.5151508761210019}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 2, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c443e358d51643e3b4ba130f660bf6fb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.26625416544087405, 'mcrmse': 0.5148894551538864}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 2, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb80cc262d8c401da9a1e0ec2b9c667c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.24033226423403797, 'mcrmse': 0.4898599293632733}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 1.1386658753961554}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3d154411d7a46a4b6832b106c05d5a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2270686841758011, 'mcrmse': 0.4759330252416831}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb2bc66d4d1c4389bc722c09cab2b3c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0a0d41f7a92442898140fe39c74844d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2476841225038709, 'mcrmse': 0.4973354292486793}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adbfe6af37974f90ac08ff545a33d5c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22821514620957778, 'mcrmse': 0.4769009423657054}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50874f0a4b3542169442ef18c0053c4f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22526928637643603, 'mcrmse': 0.4740992519960958}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.246529628572714}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6cc8b283b5b425eba57e1b6c932b913","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21954712828102013, 'mcrmse': 0.4678102960068939}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5adca5f4a90a42f2a8af11d39bfa85a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bba15c591e58429ab11be928b1e0cb31","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22267688151515658, 'mcrmse': 0.4716282667992548}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a8181069c154d80bc779ad248a152e4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22145361239876588, 'mcrmse': 0.46970291589496443}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42700129de19408e8d06412e2fc9aa60","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21413777345586615, 'mcrmse': 0.46211688668236434}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.2215239016524971}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"892386be10f345009217361afaf0ce1f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2136422331680727, 'mcrmse': 0.46162381789520396}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6d94d6a52c84602863f72a7e20036ce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62cb9ffd66c0424e8dbc03dfd4ff04b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2132833627102625, 'mcrmse': 0.46123806025959785}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 2, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e96ad0cedcd44ac997003ef82d3953f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2111739862300551, 'mcrmse': 0.4590441666576394}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 2, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79e62020773a4fb5bfd7b2282f9911d8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21033196966818837, 'mcrmse': 0.4580507248416523}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.20567324166864995}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d96ffda2a974c6691f56c7e82537ff4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21082617563512318, 'mcrmse': 0.4586320075588816}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2cec4badf8e4b05b8438ef2824d4da7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a36e938f37b448b4a5878b3a94a7ca38","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2933365660707664, 'mcrmse': 0.5407064602568884}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 3, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"896066ad6948447c9856f5e02ad8e88b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2381936431007312, 'mcrmse': 0.48753969907212347}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 3, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bc3d1a906cc4d7faa679bfe2efd6097","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23960225074492453, 'mcrmse': 0.4886534411440178}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 1.002688156559949}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae525194473645b688458bc110f3a97d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2245694169836581, 'mcrmse': 0.4727254539895607}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65c5c909bd13456da62109413b1d3a99","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9ffb81c79a340a982225930858bdb88","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21724616181667503, 'mcrmse': 0.46526973335622257}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 3, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d407accdf82424586d98c825ff82d2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22221723214134842, 'mcrmse': 0.47048969029477045}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"adc12879670345afaa762e0e623c7079","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22733250043123884, 'mcrmse': 0.4763907918999181}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.2615710608375347}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f13cee08e62420081c4fb305cc89d57","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2111488106991629, 'mcrmse': 0.458940369044518}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f506b1ab090b4185bdafd701c66bc791","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a77d281ea0e44159b13143b64f42cce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21047294761061364, 'mcrmse': 0.4581766708755361}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 3, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fe78b22c8d14e688b251a5bce2f50a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21198621719999386, 'mcrmse': 0.45981039438785865}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ba35015edd54574bbd27a03419b66d1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21201794851771402, 'mcrmse': 0.4599448273253261}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.23492505231781688}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91798aec607e4cd99b2d707ad5bab4f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21467091356549423, 'mcrmse': 0.46258451567032527}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c7b48aef4e141d2a099e671ad0428b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fb53b9cf82b4d94937982518174a715","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2095590028768915, 'mcrmse': 0.45706277180321897}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 3, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c846231efeb2469e88044e02a19e87e7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20863160426202026, 'mcrmse': 0.4560010533595773}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 3, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b50a2e153ad84a4586b0c783b1834a39","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20642762572106804, 'mcrmse': 0.4536861630211695}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.21685148720317485}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f3b671fc44d4c6e8e421b87acba6760","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2058411720387466, 'mcrmse': 0.45305319983099346}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a9fdeab3be24d7abe31022c67bfd034","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3301190639f8413497fabe846da9c4b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.27512077606090196, 'mcrmse': 0.5229452514686869}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 4, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06e18ee3cc5d4dfe958417d2cbbb2b03","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22177275344538872, 'mcrmse': 0.47031277072492367}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 4, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2a52f28ae5e437b93f6685dfdbe780e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.24266815437075426, 'mcrmse': 0.49187946659676}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 1.021398965698069}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44140fc804d14e0782f07324788bf3ea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2158304828283427, 'mcrmse': 0.46414071532062934}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20037f853b184c0caef02cdcaa0515d4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93e15c1d894a495eb47c97e0a6a75ed5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21558159067655158, 'mcrmse': 0.4636904591531786}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 4, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc8130d1ba9449d28944c45f45b72096","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21841148079356268, 'mcrmse': 0.4666045702356451}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7797f505b05a4d82873ad09d94483883","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21060508828791205, 'mcrmse': 0.4582634208395575}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.25253800944903926}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2cce0bba7ce45ea823f19fd2d2ad4c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2232227011409867, 'mcrmse': 0.47125839576815887}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73e374fb03504096be61fa70fe1959d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2b75609971642b3ba5de40f4b710460","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2082841255895012, 'mcrmse': 0.45594502377185736}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 4, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd278894bb5a4237a87b90772b865e10","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2127165855730281, 'mcrmse': 0.4603637337976793}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52093912f3c048b49356455375c3a4b5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2153731462214609, 'mcrmse': 0.46328627685661233}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.22855898179590245}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d360c93269242a2a8084519fdf822d6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20799440309367218, 'mcrmse': 0.4556597243079789}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e8f96ac5ee841aab3a5943a5399d971","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c39449dfc07746328ded7e870a40cba8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20643756090832488, 'mcrmse': 0.45391702410553486}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","fold: 4, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e88ee3b57544ed298b45a273affb738","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21663217930613882, 'mcrmse': 0.46443191143034124}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb623c6f4c6a4893ad7160d6808ce670","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20578923608031113, 'mcrmse': 0.45314025415113907}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n"]},{"data":{"text/plain":["{'train_loss': 0.21415980049716238}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d73277f60f374c4686f80eb8b269f435","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20523188463257402, 'mcrmse': 0.45251162242548554}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","CV: 0.4553\n","Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8.09G/8.09G [03:30\u003c00:00, 41.3MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (8GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:02\u003c00:00, 3.58kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 180k/180k [00:01\u003c00:00, 129kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (180KB)\n","Starting upload for file tokenizer.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.36M/2.36M [00:03\u003c00:00, 821kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: tokenizer.tar (2MB)\n","Starting upload for file modelconfig.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.55k/2.55k [00:01\u003c00:00, 1.39kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: modelconfig.pth (3KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train_folds.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","train = processing_features(train)\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","cfg.folds = get_multilabelstratifiedkfold(train, [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"], cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PwTIVNWuwErN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO/1HnjdAO8jQ315qegD2QA","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"16c_PSkctEMBMLSiJBt5lcUyW8HaWheaJ","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}