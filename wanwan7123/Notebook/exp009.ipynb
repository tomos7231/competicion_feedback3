{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1662361469065,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"9b34df74-9a47-44b4-c85d-a399b071d32e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Sep  5 07:04:28 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"feedback3-Exp009-deberta-v3-large\"\n","    MODEL_PATH = \"microsoft/deberta-v3-large\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"feedback-prize-english-learning\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback3\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 42\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 8\n","    n_epochs = 4\n","    max_len = 756\n","    \n","    weight_decay = 0.001\n","    beta = (0.9, 0.999)\n","    lr = 1e-5\n","    eval_step = 100\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","    \n","    # GPU Optimize Settings\n","    gpu_optimize_config= {\n","        \"gradient_checkpoint\": True\n","    }\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3qpAE-53Teb","outputId":"70c0e4be-d294-4a2a-b14f-f86ebf248e75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting iterative-stratification\n","  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.7.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n","Installing collected packages: iterative-stratification\n","Successfully installed iterative-stratification-0.1.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.10\n","  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:43tcmalloc: large alloc 1147494400 bytes == 0x39bb0000 @  0x7f8e9358c615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10) (4.1.1)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","from sklearn.metrics import mean_squared_error\n","\n","! pip install iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","! pip install torch==1.10\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.checkpoint import checkpoint\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_multilabelstratifiedkfold(train, target_col, n_splits, seed):\n","    kf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"559M6w8N4j95"},"outputs":[],"source":["# バッチごとにパディング操作を行う\n","class Collate:\n","    def __init__(self, tokenizer, return_label=False):\n","        self.tokenizer = tokenizer\n","        self.return_label = return_label\n","\n","    def __call__(self, batch):\n","        labels =  [label for _, label in batch]\n","        batch = [_batch for _batch, _ in batch]\n","\n","        output = dict()\n","\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(token_id) for token_id in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","\n","        if self.return_label:\n","            labels = torch.tensor([sample for sample in labels], dtype=torch.half)\n","\n","        return output, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NX6HXpH8gWUV"},"outputs":[],"source":["# 文章のバグを治す\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9c3uiSU3mDy"},"outputs":[],"source":["# =====================\n","# Dataset, Model\n","# =====================\n","\n","def processing_features(df):\n","    df['text'] = df['full_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n","    return df\n","\n","# dataset\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.text = df['text'].to_numpy()\n","        self.labels = df[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].to_numpy()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.text[index])\n","        label = torch.tensor(self.labels[index], dtype=torch.half)\n","        return inputs, self.labels[index]\n","\n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(text,\n","                               add_special_tokens=True,\n","                               max_length=cfg.max_len,\n","                               padding=\"max_length\",\n","                               truncation=True,\n","                               return_offsets_mapping=False)\n","        return inputs\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.gpu_optimize_config = cfg.gpu_optimize_config\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout\": 0.,\n","                \"hidden_dropout_prob\": 0.,\n","                \"attention_dropout\": 0.,\n","                \"attention_probs_dropout_prob\": 0,\n","                \"layer_norm_eps\": 1e-7,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": 6,\n","            }\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","\n","        # Gradient Checkpointing\n","        if self.gpu_optimize_config['gradient_checkpoint']:\n","            self.backbone.gradient_checkpointing_enable()  \n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, inputs, labels):\n","        outputs = self.backbone(**inputs)\n","        last_hidden_state = outputs[0]\n","        out = self.layer_norm1(last_hidden_state[:, 0, :])\n","        logits1 = self.fc(self.dropout1(out))\n","        logits2 = self.fc(self.dropout2(out))\n","        logits3 = self.fc(self.dropout3(out))\n","        logits4 = self.fc(self.dropout4(out))\n","        logits5 = self.fc(self.dropout5(out))\n","        output = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        if labels is not None:\n","            loss_fct = nn.MSELoss()\n","            loss = loss_fct(output, labels)\n","            return loss, output\n","        else:\n","            return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPeBFK41drE5"},"outputs":[],"source":["def get_optimizer_grouped_parameters(model):\n","    model_type = 'backbone'\n","    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'regressor' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": cfg.lr,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n","    layers.reverse()\n","    lr = cfg.lr\n","    for layer in layers:\n","        lr *= 0.95\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": cfg.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","    return optimizer_grouped_parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CuPiR3hOlMMY"},"outputs":[],"source":["# def metric\n","def mcrmse(preds, df):\n","    score0 = np.sqrt(mean_squared_error(preds[:, 0], df['cohesion']))\n","    score1 = np.sqrt(mean_squared_error(preds[:, 1], df['syntax']))\n","    score2 = np.sqrt(mean_squared_error(preds[:, 2], df['vocabulary']))\n","    score3 = np.sqrt(mean_squared_error(preds[:, 3], df['phraseology']))\n","    score4 = np.sqrt(mean_squared_error(preds[:, 4], df['grammar']))\n","    score5 = np.sqrt(mean_squared_error(preds[:, 5], df['conventions']))\n","    return (score0 + score1 + score2 + score3 + score4 + score5)/6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def evaluating(cfg, valid_loader, model, criterion, valid_df, fold, best_val_preds, best_val_score):\n","    val_preds = []\n","    val_losses = []\n","    val_nums = []\n","    model.eval()\n","    with torch.no_grad():\n","        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","            for (inputs, labels) in pbar:\n","                for k, v in inputs.items():\n","                    inputs[k] = v.to(cfg.device)\n","                labels = labels.to(cfg.device)\n","                with autocast():\n","                    loss, output = model(inputs, labels)\n","                \n","                output = output.detach().cpu().numpy()\n","                val_preds.append(output)\n","                val_losses.append(loss.item() * len(labels))\n","                val_nums.append(len(labels))\n","                pbar.set_postfix({\n","                    'val_loss': loss.item()\n","                })\n","\n","    val_preds = np.concatenate(val_preds)\n","    val_loss = sum(val_losses) / sum(val_nums)\n","    score = mcrmse(val_preds, valid_df)\n","\n","    val_log = {\n","        'val_loss': val_loss,\n","        'mcrmse': score\n","    }\n","    display(val_log)\n","\n","    if best_val_score > score:\n","        print('\\033[31m'+'save model weight'+'\\033[0m')\n","        best_val_preds = val_preds\n","        best_val_score = score\n","        torch.save(\n","            model.state_dict(), \n","            os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","        )\n","    \n","    return best_val_preds, best_val_score\n","\n","def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros((len(train), 6), dtype=np.float32)\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        # Datasetの設定\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False,\n","            collate_fn = Collate(cfg.tokenizer, return_label=True)\n","        )\n","\n","        # model\n","        model = CustomModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        optimizer_grouped_parameters = get_optimizer_grouped_parameters(model)\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","\n","        # model-training\n","        criterion = nn.MSELoss()\n","        best_val_preds = None\n","        best_val_score = 9999\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            train_losses = []\n","            train_nums = []\n","            model.train() \n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        loss, output = model(inputs, labels)\n","\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","                    train_losses.append(loss.item() * len(labels))\n","                    train_nums.append(len(labels))\n","\n","                    if cfg.gradient_accumulation_steps > 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","                    if step % cfg.eval_step == 0 and step != 0:\n","                        print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n","                        best_val_preds, best_val_score = evaluating(\n","                            cfg, valid_loader,\n","                            model,\n","                            criterion,\n","                            valid_df,\n","                            fold,\n","                            best_val_preds,\n","                            best_val_score\n","                        )\n","                        model.train()\n","\n","            train_loss = sum(train_losses)/sum(train_nums)\n","            train_log = {\n","                'train_loss':train_loss\n","            }\n","            display(train_log)\n","\n","            # evaluating(epoch)\n","            print(f'fold: {fold}, epoch: {epoch}, complete')\n","            best_val_preds, best_val_score = evaluating(\n","                cfg, valid_loader,\n","                model,\n","                criterion,\n","                valid_df,\n","                fold,\n","                best_val_preds,\n","                best_val_score\n","            )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    score = mcrmse(oof_pred, train)\n","    print('CV:', round(score, 4))\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["5b177577c2ef46aeb1db199284d6691b","2516f4105bbe4b458a37fda359fb1953","896b4abed62b4e93bb0fe75a0e01eacb","687ba66ce86c48d1b595499cab351fc1","03271622ac004c8eaaf52f2fbc5a7f27","4c45e90501d54897a439ca593705963d","2a6efada7aa2466685cc0bdc67da74c6","9166ca32ddb245d2b2a8d4d85778c3b8","8a6e01fa860048028d693560ccc90498","d0a22420acb54c95a1b3efc1c0d4416b","49b252b40f384382806c7578640823ca","6bb11c09d63448dcb8bebf6102fb4f52","aeeaec2d1b3e4a26acd8cd63986a2582","bb6cd84317eb4eb086a860f13bd0cc65","dde823e7d6ff497182edcf562838a87d","2af3a37e1fb54fd59c93081f3e562022","5f8c89a0fc3b402eb66efc39ab5a6838","e2a39ed1ce2a495b90299000b47ef36b","2d82b3c700624dc48ea50245a25f9a2c","4d49bdbb5b0146738fbd501aab66c750","0822a14724534c4c8d847123eae23f09","9557eb9fd9624e96950e8dba69f5f5c1","5d19718fee7445bea200e4d0a66ccd4d","c10a0b4c36a84476bdcd15ad59500a3b","7a913ce9115b4f8c997919ec5a0d6d0b","07f1756be97043189504560e9d932730","93f45a9a36f4455aa30dee045eb97b9f","fd4dda2bcddd4513b245043f6f585634","c0dda9ab99fb464badc9f9c0eb969a04","f3066e5ee741478f956159ee42e8ea5c","93d10894acb442c9a4f808729c259233","9d799945cb80494aa692b1ff64b9eef3","53b7d5e2bb2f4c119bf03f8c15a94d13","7f4a73a730ee4c90983da46965529f34","b22bfdcc36134d24bf82862cc85a3c77","29b6535dbafd4b569ba600cf80be4d12","546bdf3e2c5b40e38f0d4122a61e4346","37c09f7de2244767bd8a5fa86d7ac1b4","3d888903f3064958a23208ccd86d7c5a","5fb66fa7168342059bd1f0eda890a9ba","4bd4f5539ae64bbf8ff3e5675ac752cd","b9681eb7f39d4eef9f1ed8181d475f16","aa3963567d35415db8ba65599362ff34","52516222c90e4cdeb0937197c5905222","290e954c60ac4859bd2ae07088e76beb","5bb2b041681e4c59ad3b5ab8e0d363a1","c1e2a69fa58d4495bd6c908450c78a8d","dcfd57364e7a47969bf639aa55276f12","0248584a898449549bc104a19d9cfa3b","5cf0358a4f4b41cb8569c7d7d1d21c96","535a65e0523f45bcafeb0870fcf0e7ec","d80381de24984e28a6ed447ce91d1442","a179316e63ba478a8cc71f3bd489c1f6","662020c4a87141d3963f35ff255e380d","c9b65b4bfbfd46aaad2cbd06d14556b0","07d77d7b09444738b0226841e8fbced1","924db24af3e94bbdb9e75638bd2bfbea","2dd2971f4bc74dcd9b1225b34c3a34ca","fe346dd7961540a7b14d77338cd6f910","cd6a4e839d9d4426a61144910f1e0f97","71f2c7052c534e26ad56a80456492bf7","46be33b5639f46dc9a26cd312ddd9715","07b0ddaea0ee497ab61d2b02cf5ad326","43960785c8044b6994048fec3bbbc18c","d173bb304f0f4a8198c661e0825a0901","36f8ef24af81433eb657f4de4b7b73b7","8dcc010e1c9a417bb1b4738a667987c3","a8c37f4a6ac74f6d87ed8070bd718a5c","d3302c3d49464a96b35e844f3b50fbc6","13467a2697bf40dd93b1e1730d2d33c9","2303f5c0c55e461db06181215d1cbd65","931bce2ce5d34188a820065a4b869a37","eb07eb60cdf040de8e068e04266f9453","90223e9b8a974902bc3e473dc04c3807","8793a73e13fd400bb049f11a9746cbe5","31eb94073e8741008e7640c1d0590bcc","c88b5c11a66a4820afbe07ab6f4be6c5","7b8c0b03da4744709a00411fc15a8253","4ce9f7980b0e431083ebba4d6a859242","2d1168e1a24e4302a9cdff5315dbe651","523006b56d8a49589c9a3d15637e14be","4474fe319c4b47fd9496d710c05ff161","16d003d032dc4071a14a91fa760383d3","8f31d0411c654c2db880925a3ee88576","bdd97789669241eca502233835265783","9e3acc88059f418b9e6e2c7ecc7c6bce","45ad54c9e1804bcb892cf7b3a0948f29","17a32f84aaa145088bbebf972e64c38d","fe2d2897fe37436fad48d22d1b0ef3fc","c95c7abebfc94230af4fe0f70460c1ce","9eee816b9f984c7b8084b6af934f5ae1","4f09d58b6e9941aa8bc53cac212b90d3","61085a90a5534ca1a3104769c0ab0935","385a40090cc1428e82ea0f8f8a4d3cb1","23755e38ab1f4c668931ad082e9ad305","7d1a0e114e0f41c5971aaebc969242e3","866866918aad45e2b5e0dceca3b17866","38c636f16149436ebd4a57ed0528cef6","ea45fa317e09475295dc5da315f73593","1a7df356afd648a49af4f44ab32d9a43","a05dffaf95e9400bbe7059f81361a8fb","22ac562d5e504759aa372b48b73fa60e","b3bcf183629f47d1b0b3cde251135cbf","fd95c97470884e479c2270ca059c6a32"]},"id":"gSrrvDWVpxN_","outputId":"0102028e-9c84-43c0-ac17-d3f3756d259f"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.16.2\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 13.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 87.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 79.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 83.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.16.2) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.16.2) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=12ca43059105855256e6a7363a59f025554c606944d5cab29a5f1629a9f1750d\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.16.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers==0.11.6\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 15.0 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","Successfully installed tokenizers-0.11.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.9.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.8.0)\n","Collecting sentencepiece!=0.1.92,>=0.1.91\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 15.4 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b177577c2ef46aeb1db199284d6691b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2516f4105bbe4b458a37fda359fb1953","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"896b4abed62b4e93bb0fe75a0e01eacb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"687ba66ce86c48d1b595499cab351fc1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03271622ac004c8eaaf52f2fbc5a7f27","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c45e90501d54897a439ca593705963d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.31570270173537457, 'mcrmse': 0.5602804879406346}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a6efada7aa2466685cc0bdc67da74c6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23138602863034935, 'mcrmse': 0.4800777683418886}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9166ca32ddb245d2b2a8d4d85778c3b8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2222960620661221, 'mcrmse': 0.4708283125097145}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 1.1196422718674934}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a6e01fa860048028d693560ccc90498","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.24632832263131885, 'mcrmse': 0.495391940820235}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0a22420acb54c95a1b3efc1c0d4416b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49b252b40f384382806c7578640823ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2186430765844672, 'mcrmse': 0.4670781050323343}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6bb11c09d63448dcb8bebf6102fb4f52","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22769863568151089, 'mcrmse': 0.4767900618201894}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aeeaec2d1b3e4a26acd8cd63986a2582","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21672211240624528, 'mcrmse': 0.464941210746495}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.25407833981392025}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb6cd84317eb4eb086a860f13bd0cc65","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2178504140785588, 'mcrmse': 0.4665060490868236}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dde823e7d6ff497182edcf562838a87d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2af3a37e1fb54fd59c93081f3e562022","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2106715172071896, 'mcrmse': 0.4584146602893693}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 0, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f8c89a0fc3b402eb66efc39ab5a6838","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.239865115803221, 'mcrmse': 0.48916354895514463}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2a39ed1ce2a495b90299000b47ef36b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21011119170109635, 'mcrmse': 0.4577699350451714}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.22966308144809644}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d82b3c700624dc48ea50245a25f9a2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2056302369555549, 'mcrmse': 0.45299505877020313}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d49bdbb5b0146738fbd501aab66c750","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0822a14724534c4c8d847123eae23f09","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20750981378738229, 'mcrmse': 0.4549082202340345}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9557eb9fd9624e96950e8dba69f5f5c1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20911000928153162, 'mcrmse': 0.45662825668666857}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d19718fee7445bea200e4d0a66ccd4d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2061762173691064, 'mcrmse': 0.45345337230449734}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.21487160505312483}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 0, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c10a0b4c36a84476bdcd15ad59500a3b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20847963261634797, 'mcrmse': 0.45597892909263216}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a913ce9115b4f8c997919ec5a0d6d0b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07f1756be97043189504560e9d932730","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.27655553383845477, 'mcrmse': 0.5254240983315527}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93f45a9a36f4455aa30dee045eb97b9f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23588917667990594, 'mcrmse': 0.4847717178348327}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd4dda2bcddd4513b245043f6f585634","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22656395879132843, 'mcrmse': 0.4752912151362625}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.8940184415911164}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0dda9ab99fb464badc9f9c0eb969a04","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21747419123905373, 'mcrmse': 0.4657652486678761}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3066e5ee741478f956159ee42e8ea5c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93d10894acb442c9a4f808729c259233","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22043838293920837, 'mcrmse': 0.4687700730789565}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d799945cb80494aa692b1ff64b9eef3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21382848398895557, 'mcrmse': 0.461884812290471}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53b7d5e2bb2f4c119bf03f8c15a94d13","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2200983388213819, 'mcrmse': 0.4684078838810257}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.24579262611506236}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f4a73a730ee4c90983da46965529f34","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2146516376071506, 'mcrmse': 0.46273952906348653}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b22bfdcc36134d24bf82862cc85a3c77","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29b6535dbafd4b569ba600cf80be4d12","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20847394027167962, 'mcrmse': 0.4560060652147952}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"546bdf3e2c5b40e38f0d4122a61e4346","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2169732779530882, 'mcrmse': 0.4650245938470443}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37c09f7de2244767bd8a5fa86d7ac1b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22334353665739184, 'mcrmse': 0.47218489261280955}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.22685847425704722}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d888903f3064958a23208ccd86d7c5a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22390404488239557, 'mcrmse': 0.4726383499196942}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fb66fa7168342059bd1f0eda890a9ba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bd4f5539ae64bbf8ff3e5675ac752cd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20895347212313997, 'mcrmse': 0.4564807369215253}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9681eb7f39d4eef9f1ed8181d475f16","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20776433209349826, 'mcrmse': 0.45525855634490847}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 1, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa3963567d35415db8ba65599362ff34","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20840042448896406, 'mcrmse': 0.4559845484635631}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.21304774657844583}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 1, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52516222c90e4cdeb0937197c5905222","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20717329178885635, 'mcrmse': 0.45460197626138027}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"290e954c60ac4859bd2ae07088e76beb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bb2b041681e4c59ad3b5ab8e0d363a1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.27334921039126414, 'mcrmse': 0.521612151022582}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1e2a69fa58d4495bd6c908450c78a8d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.24962166481463197, 'mcrmse': 0.4987461300801617}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dcfd57364e7a47969bf639aa55276f12","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23120824424811945, 'mcrmse': 0.4801704709099303}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 1.2005551679588644}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0248584a898449549bc104a19d9cfa3b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22303908057225025, 'mcrmse': 0.4715562932334932}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5cf0358a4f4b41cb8569c7d7d1d21c96","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"535a65e0523f45bcafeb0870fcf0e7ec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.24408000357010784, 'mcrmse': 0.4937681184009987}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d80381de24984e28a6ed447ce91d1442","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2212430558851003, 'mcrmse': 0.4696646472562221}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a179316e63ba478a8cc71f3bd489c1f6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22248484449618308, 'mcrmse': 0.4711135315973433}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.24486527067925923}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"662020c4a87141d3963f35ff255e380d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21753040523937597, 'mcrmse': 0.46567757103137297}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9b65b4bfbfd46aaad2cbd06d14556b0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07d77d7b09444738b0226841e8fbced1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21461621151708277, 'mcrmse': 0.4628232194661059}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"924db24af3e94bbdb9e75638bd2bfbea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22608781383013177, 'mcrmse': 0.47440669526484686}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dd2971f4bc74dcd9b1225b34c3a34ca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2129576911630533, 'mcrmse': 0.4608892146228419}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.22584811121682682}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe346dd7961540a7b14d77338cd6f910","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21284371770708763, 'mcrmse': 0.4605785805611851}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd6a4e839d9d4426a61144910f1e0f97","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71f2c7052c534e26ad56a80456492bf7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21296949574099783, 'mcrmse': 0.4608857029304076}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46be33b5639f46dc9a26cd312ddd9715","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21124094050101308, 'mcrmse': 0.4590801839987149}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 2, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07b0ddaea0ee497ab61d2b02cf5ad326","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20982142128145603, 'mcrmse': 0.4574728874337813}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.21050628674838245}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 2, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43960785c8044b6994048fec3bbbc18c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20940800205520962, 'mcrmse': 0.4570506638380987}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d173bb304f0f4a8198c661e0825a0901","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36f8ef24af81433eb657f4de4b7b73b7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.3289560537661433, 'mcrmse': 0.5722263999433365}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8dcc010e1c9a417bb1b4738a667987c3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22777780513171955, 'mcrmse': 0.47663703465111357}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8c37f4a6ac74f6d87ed8070bd718a5c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2269229469701762, 'mcrmse': 0.47546161864061887}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 1.0390569747942489}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3302c3d49464a96b35e844f3b50fbc6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2234425488716501, 'mcrmse': 0.4716420068113454}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13467a2697bf40dd93b1e1730d2d33c9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2303f5c0c55e461db06181215d1cbd65","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21587357180350272, 'mcrmse': 0.4636994190894556}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"931bce2ce5d34188a820065a4b869a37","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22068923010545619, 'mcrmse': 0.4689672364165682}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb07eb60cdf040de8e068e04266f9453","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23321132628661592, 'mcrmse': 0.4824297204782441}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.2563744567887253}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90223e9b8a974902bc3e473dc04c3807","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21200909459834819, 'mcrmse': 0.4599032654668694}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8793a73e13fd400bb049f11a9746cbe5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31eb94073e8741008e7640c1d0590bcc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21245033734137445, 'mcrmse': 0.46033675388285306}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c88b5c11a66a4820afbe07ab6f4be6c5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21110300586351652, 'mcrmse': 0.45876490957152377}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b8c0b03da4744709a00411fc15a8253","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21061798945412308, 'mcrmse': 0.45833064552375474}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.23460909104941752}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ce9f7980b0e431083ebba4d6a859242","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2120745778846009, 'mcrmse': 0.4597321115191841}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d1168e1a24e4302a9cdff5315dbe651","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"523006b56d8a49589c9a3d15637e14be","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21057014742775645, 'mcrmse': 0.45811751658288596}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4474fe319c4b47fd9496d710c05ff161","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20881323055233186, 'mcrmse': 0.4562084880407386}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 3, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16d003d032dc4071a14a91fa760383d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20610329901318417, 'mcrmse': 0.45329873741643234}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.22143621411165007}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 3, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f31d0411c654c2db880925a3ee88576","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20537087233627543, 'mcrmse': 0.45249586497334154}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdd97789669241eca502233835265783","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e3acc88059f418b9e6e2c7ecc7c6bce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2562832751542406, 'mcrmse': 0.505163845683577}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 0, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45ad54c9e1804bcb892cf7b3a0948f29","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22825270567251288, 'mcrmse': 0.47706734918093735}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 0, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17a32f84aaa145088bbebf972e64c38d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.23384581837812654, 'mcrmse': 0.48299717745844095}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 1.098802538517186}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 0, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe2d2897fe37436fad48d22d1b0ef3fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21565281150057491, 'mcrmse': 0.4639163818056285}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c95c7abebfc94230af4fe0f70460c1ce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9eee816b9f984c7b8084b6af934f5ae1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21709039041300868, 'mcrmse': 0.465367534433008}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f09d58b6e9941aa8bc53cac212b90d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2152657822879684, 'mcrmse': 0.46330204693476434}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 1, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61085a90a5534ca1a3104769c0ab0935","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2123024539493234, 'mcrmse': 0.46009411392445937}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.2547145398986309}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 1, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"385a40090cc1428e82ea0f8f8a4d3cb1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.22223652967863985, 'mcrmse': 0.4703441681814617}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23755e38ab1f4c668931ad082e9ad305","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d1a0e114e0f41c5971aaebc969242e3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20954003789083428, 'mcrmse': 0.4573301127390806}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 2, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"866866918aad45e2b5e0dceca3b17866","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.21394389753451432, 'mcrmse': 0.46165249629333305}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38c636f16149436ebd4a57ed0528cef6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2176905272485655, 'mcrmse': 0.4657790771716987}"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'train_loss': 0.23303897581670596}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 2, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea45fa317e09475295dc5da315f73593","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20919912855338563, 'mcrmse': 0.4569703856197223}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a7df356afd648a49af4f44ab32d9a43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 100\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a05dffaf95e9400bbe7059f81361a8fb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2073470915636748, 'mcrmse': 0.45494946509031964}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","fold: 4, epoch: 3, step: 200\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22ac562d5e504759aa372b48b73fa60e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.217460999079525, 'mcrmse': 0.4653569495632035}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, step: 300\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3bcf183629f47d1b0b3cde251135cbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.2065434416427332, 'mcrmse': 0.4539957114974424}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n"]},{"data":{"text/plain":["{'train_loss': 0.22192823096080813}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["fold: 4, epoch: 3, complete\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd95c97470884e479c2270ca059c6a32","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/98 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'val_loss': 0.20619492410012827, 'mcrmse': 0.453590190304993}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[31msave model weight\u001b[0m\n","CV: 0.4542\n","Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8.09G/8.09G [03:46<00:00, 38.3MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (8GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:01<00:00, 5.32kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 180k/180k [00:01<00:00, 102kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (180KB)\n","Starting upload for file tokenizer.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.36M/2.36M [00:03<00:00, 807kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: tokenizer.tar (2MB)\n","Starting upload for file modelconfig.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.55k/2.55k [00:02<00:00, 1.15kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: modelconfig.pth (3KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train_folds.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","train = processing_features(train)\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","cfg.folds = get_multilabelstratifiedkfold(train, [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"], cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PwTIVNWuwErN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","provenance":[],"mount_file_id":"16c_PSkctEMBMLSiJBt5lcUyW8HaWheaJ","authorship_tag":"ABX9TyPgrDTI9GFP7xIn5AlMVxRT"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}