{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3QT3hl827yR",
    "outputId": "9df43b98-7ff1-4537-ebc0-f746429cf935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 24 13:21:21 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   40C    P8    15W / 300W |      0MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iri53t0J3Ma0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Config:\n",
    "    AUTHOR = \"wanwan7123\"\n",
    "\n",
    "    NAME = \"feedback3-Exp060-deberta-v3-base\"\n",
    "    MODEL_PATH = \"microsoft/deberta-v3-base\"\n",
    "    DATASET_PATH = []\n",
    "\n",
    "    COMPETITION = \"feedback-prize-english-learning\"\n",
    "    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competicion_feedback3\" \n",
    "    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n",
    "\n",
    "    api_path = \"kaggle_json/kaggle.json\"\n",
    "\n",
    "    apex=False\n",
    "    seed = 42\n",
    "    num_fold = 10\n",
    "    trn_fold = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    batch_size = 16\n",
    "    n_epochs = 5\n",
    "    max_len = 1024\n",
    "    target_list = [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]\n",
    "    \n",
    "    weight_decay = 0.01\n",
    "    scheduler = 'cosine'\n",
    "    betas = (0.9, 0.999)\n",
    "    encoder_lr = 3e-5\n",
    "    decoder_lr = 3e-5\n",
    "    layer_wise_decay = 0.4\n",
    "    hidden_weight_lr = 1e-2\n",
    "    min_lr = 1e-6\n",
    "    eps = 1e-6\n",
    "    eval_step = 40\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps_rate=0.1\n",
    "    clip_grad_norm = None\n",
    "    gradient_accumulation_steps = 1\n",
    "    \n",
    "    awp_eps = 1e-2\n",
    "    awp_lr = 1e-5\n",
    "    awp_start = 1\n",
    "    \n",
    "    # GPU Optimize Settings\n",
    "    gpu_optimize_config= {\n",
    "        \"freezing\": False,\n",
    "        \"gradient_checkpoint\": True\n",
    "    }\n",
    "\n",
    "    upload_from_colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3qpAE-53Teb",
    "outputId": "eda36ecb-e3b4-4fb3-b1f3-079ad18ea3d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.1.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from iterative-stratification) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->iterative-stratification) (1.1.0)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.10.1+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.1%2Bcu113-cp39-cp39-linux_x86_64.whl (1821.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.1+cu113) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0+cu116\n",
      "    Uninstalling torch-1.12.0+cu116:\n",
      "      Successfully uninstalled torch-1.12.0+cu116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.0+cu116 requires torch==1.12.0, but you have torch 1.10.1+cu113 which is incompatible.\n",
      "torchaudio 0.12.0+cu116 requires torch==1.12.0, but you have torch 1.10.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.10.1+cu113\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting text-unidecode\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: text-unidecode\n",
      "Successfully installed text-unidecode-1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import joblib\n",
    "import random\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, \n",
    "    KFold, \n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "! pip install iterative-stratification\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "! pip install torch==1.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "!pip install text-unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5zS5FvS83UY_"
   },
   "outputs": [],
   "source": [
    "def setup(cfg):\n",
    "    cfg.COLAB = 'google.colab' in sys.modules\n",
    "    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # pip install\n",
    "    ! pip install transformers==4.16.2\n",
    "    ! pip install tokenizers==0.11.6\n",
    "    ! pip install transformers[sentencepiece]\n",
    "\n",
    "    # use kaggle api (need kaggle token)\n",
    "    f = open(cfg.api_path, 'r')\n",
    "    json_data = json.load(f) \n",
    "    os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
    "    os.environ['KAGGLE_KEY'] = json_data['key']\n",
    "\n",
    "    # set dirs\n",
    "    cfg.INPUT = 'input'\n",
    "    cfg.EXP = cfg.NAME\n",
    "    cfg.OUTPUT_EXP = cfg.NAME\n",
    "    cfg.SUBMISSION = './'\n",
    "    cfg.DATASET = '../input/'\n",
    "\n",
    "    cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n",
    "    cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n",
    "    cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n",
    "\n",
    "    # make dirs\n",
    "    for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def dataset_create_new(dataset_name, upload_dir):\n",
    "    dataset_metadata = {}\n",
    "    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n",
    "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
    "    dataset_metadata['title'] = dataset_name\n",
    "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=4)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rQS0vaZd8A8-"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Utils\n",
    "# =====================\n",
    "# Seed\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# KFold\n",
    "def get_kfold(train, n_splits, seed):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train)\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_stratifiedkfold(train, target_col, n_splits, seed):\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train, train[target_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_groupkfold(train, target_col, group_col, n_splits):\n",
    "    kf = GroupKFold(n_splits=n_splits)\n",
    "    generator = kf.split(train, train[target_col], train[group_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n",
    "    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train, train[target_col], train[group_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series\n",
    "\n",
    "def get_multilabelstratifiedkfold(train, target_col, n_splits, seed):\n",
    "    kf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    generator = kf.split(train, train[target_col])\n",
    "    fold_series = []\n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        fold_series.append(pd.Series(fold, index=idx_valid))\n",
    "    fold_series = pd.concat(fold_series).sort_index()\n",
    "    return fold_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CuPiR3hOlMMY"
   },
   "outputs": [],
   "source": [
    "def mcrmse(cfg, preds, df):\n",
    "    all_score = 0\n",
    "    for i, column in enumerate(cfg.target_list):\n",
    "        score = np.sqrt(mean_squared_error(preds[:, i], df[column]))\n",
    "        all_score += score/len(cfg.target_list)\n",
    "    return all_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NX6HXpH8gWUV"
   },
   "outputs": [],
   "source": [
    "# 文章のバグを治す\n",
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N9c3uiSU3mDy"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Dataset, Model\n",
    "# =====================\n",
    "\n",
    "def processing_features(df):\n",
    "    df['text'] = df['full_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "    return df\n",
    "\n",
    "# dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.text = df['text'].to_numpy()\n",
    "        self.labels = df[cfg.target_list].to_numpy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.prepare_input(self.cfg, self.text[index])\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float)\n",
    "        return inputs, label\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(cfg, text):\n",
    "        inputs = cfg.tokenizer(text,\n",
    "                               add_special_tokens=True,\n",
    "                               max_length=cfg.max_len,\n",
    "                               padding=\"max_length\",\n",
    "                               truncation=True,\n",
    "                               return_offsets_mapping=False)\n",
    "        inputs['input_ids'] = torch.tensor(\n",
    "            inputs['input_ids'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs['attention_mask'] = torch.tensor(\n",
    "            inputs['attention_mask'],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        inputs = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "c724jYZ1Ywfg"
   },
   "outputs": [],
   "source": [
    "def freeze(module):\n",
    "    \"\"\"\n",
    "    Freezes module's parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    for parameter in module.parameters():\n",
    "        parameter.requires_grad = False\n",
    "        \n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "        nn.Linear(in_dim, in_dim),\n",
    "        nn.LayerNorm(in_dim),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(in_dim, 1),\n",
    "        )\n",
    "        \n",
    "        self._init_weights(self.attention)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        w = self.attention(last_hidden_state).float()\n",
    "        w[attention_mask==0]=float('-inf')\n",
    "        w = torch.softmax(w,1)\n",
    "        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n",
    "        return attention_embeddings\n",
    "\n",
    "# 参考：https://github.com/Danielhuxc/CLRP-solution/blob/main/components/model.py\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg): \n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.gpu_optimize_config = cfg.gpu_optimize_config\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout\": 0.,\n",
    "                \"hidden_dropout_prob\": 0.,\n",
    "                \"attention_dropout\": 0.,\n",
    "                \"attention_probs_dropout_prob\": 0,\n",
    "            }\n",
    "        )\n",
    "        self.backbone = AutoModel.from_pretrained(\n",
    "            cfg.MODEL_PATH,\n",
    "            config=self.config\n",
    "        )\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.2)\n",
    "        # self.high_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        weights_init = torch.zeros(4).float()\n",
    "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
    "\n",
    "        self.head = nn.Linear(self.config.hidden_size, 6)\n",
    "        self._init_weights(self.head)\n",
    "        \n",
    "        self.attention = AttentionPooling(self.config.hidden_size)\n",
    "        \n",
    "        self.ln = nn.LayerNorm(self.config.hidden_size)\n",
    "        self._init_weights(self.ln)\n",
    "\n",
    "        # Freeze\n",
    "        if self.gpu_optimize_config['freezing']:\n",
    "            freeze(self.transformer.encoder.layer[:8])\n",
    "\n",
    "        # Gradient Checkpointing\n",
    "        if self.gpu_optimize_config['gradient_checkpoint']:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.backbone(**inputs)\n",
    "\n",
    "        # 4層を重ねる\n",
    "        stack_outputs = torch.stack(\n",
    "            [layer for layer in outputs.hidden_states[-4:]], dim=0\n",
    "        )\n",
    "\n",
    "        # 重み付け平均（batch, length, hidden_size）\n",
    "        weighted_output = (torch.softmax(self.layer_weights, dim=0).unsqueeze(1).unsqueeze(1).unsqueeze(1) * stack_outputs).sum(0)\n",
    "\n",
    "        # 重み付け平均をattentionかける(batch, hidden_size)\n",
    "        feature = self.attention(weighted_output, inputs['attention_mask'])\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        # batch, hidden_size\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.head(self.ln(feature))\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.SmoothL1Loss(reduction='mean')\n",
    "            loss = loss_fct(output, labels)\n",
    "            return loss, output\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FzCFeRejsSF2"
   },
   "outputs": [],
   "source": [
    "from torch.autograd.function import InplaceFunction\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Mixout(InplaceFunction):\n",
    "    @staticmethod\n",
    "    def _make_noise(input):\n",
    "        return input.new().resize_as_(input)\n",
    "\n",
    "    @classmethod\n",
    "    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\" \" but got {}\".format(p))\n",
    "        if target is not None and input.size() != target.size():\n",
    "            raise ValueError(\n",
    "                \"A target tensor size must match with a input tensor size {},\"\n",
    "                \" but got {}\".format(input.size(), target.size())\n",
    "            )\n",
    "        ctx.p = p\n",
    "        ctx.training = training\n",
    "\n",
    "        if ctx.p == 0 or not ctx.training:\n",
    "            return input\n",
    "\n",
    "        if target is None:\n",
    "            target = cls._make_noise(input)\n",
    "            target.fill_(0)\n",
    "        target = target.to(input.device)\n",
    "\n",
    "        if inplace:\n",
    "            ctx.mark_dirty(input)\n",
    "            output = input\n",
    "        else:\n",
    "            output = input.clone()\n",
    "\n",
    "        ctx.noise = cls._make_noise(input)\n",
    "        if len(ctx.noise.size()) == 1:\n",
    "            ctx.noise.bernoulli_(1 - ctx.p)\n",
    "        else:\n",
    "            ctx.noise[0].bernoulli_(1 - ctx.p)\n",
    "            ctx.noise = ctx.noise[0].repeat(input.size()[0], 1)\n",
    "        ctx.noise.expand_as(input)\n",
    "\n",
    "        if ctx.p == 1:\n",
    "            output = target\n",
    "        else:\n",
    "            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        if ctx.p > 0 and ctx.training:\n",
    "            return grad_output * ctx.noise, None, None, None, None\n",
    "        else:\n",
    "            return grad_output, None, None, None, None\n",
    "\n",
    "\n",
    "def mixout(input, target=None, p=0.0, training=False, inplace=False):\n",
    "    return Mixout.apply(input, target, p, training, inplace)\n",
    "\n",
    "\n",
    "class MixLinear(torch.nn.Module):\n",
    "    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n",
    "    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n",
    "        super(MixLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "        self.reset_parameters()\n",
    "        self.target = target\n",
    "        self.p = p\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, mixout(self.weight, self.target, self.p, self.training), self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        type = \"drop\" if self.target is None else \"mix\"\n",
    "        return \"{}={}, in_features={}, out_features={}, bias={}\".format(\n",
    "            type + \"out\", self.p, self.in_features, self.out_features, self.bias is not None\n",
    "        )\n",
    "\n",
    "def replace_mixout(model):\n",
    "    for sup_module in model.modules():\n",
    "        for name, module in sup_module.named_children():\n",
    "            if isinstance(module, nn.Dropout):\n",
    "                module.p = 0.0\n",
    "            if isinstance(module, nn.Linear):\n",
    "                target_state_dict = module.state_dict()\n",
    "                bias = True if module.bias is not None else False\n",
    "                new_module = MixLinear(\n",
    "                    module.in_features, module.out_features, bias, target_state_dict[\"weight\"], 0.3\n",
    "                )\n",
    "                new_module.load_state_dict(target_state_dict)\n",
    "                setattr(sup_module, name, new_module)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vss5lmKNs4LS"
   },
   "outputs": [],
   "source": [
    "# initialize layer\n",
    "def reinit_bert(model):\n",
    "    for layer in model.backbone.encoder.layer[-1:]:\n",
    "        for module in layer.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n",
    "                if module.padding_idx is not None:\n",
    "                    module.weight.data[module.padding_idx].zero_()\n",
    "            elif isinstance(module, nn.LayerNorm):\n",
    "                module.bias.data.zero_()\n",
    "                module.weight.data.fill_(1.0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fPeBFK41drE5"
   },
   "outputs": [],
   "source": [
    "# def get_optimizer_grouped_parameters(cfg, model):\n",
    "#     model_type = 'backbone'\n",
    "#     no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
    "#     optimizer_grouped_parameters = [\n",
    "#             {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n",
    "#              'lr': cfg.decoder_lr, 'weight_decay': 0.0},\n",
    "#     ]\n",
    "#     num_layers = model.config.num_hidden_layers\n",
    "#     layers = [getattr(model, model_type).embeddings] + list(getattr(model, model_type).encoder.layer)\n",
    "#     layers.reverse()\n",
    "#     lr = cfg.encoder_lr\n",
    "#     for layer in layers:\n",
    "#         optimizer_grouped_parameters += [\n",
    "#             {\n",
    "#                 \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#                 \"weight_decay\": cfg.weight_decay,\n",
    "#                 \"lr\": lr,\n",
    "#             },\n",
    "#             {\n",
    "#                 \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#                 \"weight_decay\": 0.0,\n",
    "#                 \"lr\": lr,\n",
    "#             },\n",
    "#         ]\n",
    "        \n",
    "#         lr *= cfg.lr_weight_decay\n",
    "#     return optimizer_grouped_parameters\n",
    "\n",
    "def get_optimizer_params(model, encoder_lr, decoder_lr, hidden_weight_lr, layer_wise_decay, weight_decay=0.0):\n",
    "    named_parameters = list(model.named_parameters())\n",
    "    \n",
    "    backbone_parameters = [(n, p) for n, p in named_parameters if n.startswith('backbone')]\n",
    "    attention_parameters = [(n, p) for n, p in named_parameters if n.startswith('attention')]\n",
    "    hidden_wts_parameters = [(n, p) for n, p in named_parameters if n.startswith ('layer_weights')]\n",
    "    head_parameters = [(n, p) for n, p in named_parameters if n.startswith('head')]\n",
    "        \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    hidden_wts_group = [params for (name, params) in hidden_wts_parameters]\n",
    "    head_group = [params for (name, params) in head_parameters]\n",
    " \n",
    "    parameters = []\n",
    "    parameters.append({\"params\": attention_group})\n",
    "    parameters.append({\"params\": hidden_wts_group, 'weight_decay': 0.0, 'lr': hidden_weight_lr})\n",
    "    parameters.append({\"params\": head_group})\n",
    "\n",
    "    # bertのパラメーター\n",
    " \n",
    "    no_decay = ['bias', 'LayerNorm.weight', 'layer_norm']\n",
    "    layers = [getattr(model, 'backbone').embeddings] + list(getattr(model, 'backbone').encoder.layer)\n",
    "\n",
    "    layers.reverse()\n",
    "    layerwise_learning_rate_decay = layer_wise_decay**(1.0/len(layers))\n",
    "    lr = encoder_lr\n",
    "    for i, layer in enumerate(layers):\n",
    "        lr *= layerwise_learning_rate_decay\n",
    "        parameters += [\n",
    "            {\n",
    "                'params': [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': weight_decay,\n",
    "                'lr': lr,\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0,\n",
    "                'lr': lr,\n",
    "            },\n",
    "        ]\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=int(num_train_steps*cfg.num_warmup_steps_rate), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rp33gCv_IxCA"
   },
   "outputs": [],
   "source": [
    "# FGM\n",
    "# https://www.kaggle.com/competitions/tweet-sentiment-extraction/discussion/143764#809408\n",
    "\n",
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, epsilon=0.3, emb_name='word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "            self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "class AWP:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg,\n",
    "        model: Module,\n",
    "        optimizer: Optimizer,\n",
    "        adv_param: str=\"weight\",\n",
    "        adv_lr: float=1.0,\n",
    "        adv_eps: float=0.01\n",
    "    ) -> None:\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.adv_param = adv_param\n",
    "        self.adv_lr = adv_lr\n",
    "        self.adv_eps = adv_eps\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}\n",
    "\n",
    "    def attack_backward(self, inputs: dict, labels: Tensor) -> Tensor:\n",
    "        with autocast(enabled=self.cfg.apex):\n",
    "            self._save()\n",
    "            self._attack_step() # モデルを近傍の悪い方へ改変\n",
    "            adv_loss, _ = self.model(inputs, labels)\n",
    "            self.optimizer.zero_grad()\n",
    "        return adv_loss\n",
    "\n",
    "    def _attack_step(self) -> None:\n",
    "        e = 1e-6\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                norm1 = torch.norm(param.grad)\n",
    "                norm2 = torch.norm(param.data.detach())\n",
    "                if norm1 != 0 and not torch.isnan(norm1):\n",
    "                    # 直前に損失関数に通してパラメータの勾配を取得できるようにしておく必要あり\n",
    "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = torch.min(\n",
    "                        torch.max(\n",
    "                            param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n",
    "                    )\n",
    "\n",
    "    def _save(self) -> None:\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                if name not in self.backup:\n",
    "                    self.backup[name] = param.data.clone()\n",
    "                    grad_eps = self.adv_eps * param.abs().detach()\n",
    "                    self.backup_eps[name] = (\n",
    "                        self.backup[name] - grad_eps,\n",
    "                        self.backup[name] + grad_eps,\n",
    "                    )\n",
    "\n",
    "    def _restore(self) -> None:\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "l-kDMGg-8i-I"
   },
   "outputs": [],
   "source": [
    "def evaluating(cfg, valid_loader, model, valid_df, fold, best_val_preds, best_val_score):\n",
    "    val_preds = []\n",
    "    val_losses = []\n",
    "    val_nums = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n",
    "            for (inputs, labels) in pbar:\n",
    "                inputs = collate(inputs)\n",
    "                for k, v in inputs.items():\n",
    "                    inputs[k] = v.to(cfg.device)\n",
    "                labels = labels.to(cfg.device)\n",
    "\n",
    "                loss, output = model(inputs, labels)\n",
    "                \n",
    "                output = output.detach().cpu().numpy()\n",
    "                val_preds.append(output)\n",
    "                val_losses.append(loss.item() * len(labels))\n",
    "                val_nums.append(len(labels))\n",
    "                pbar.set_postfix({\n",
    "                    'val_loss': loss.item()\n",
    "                })\n",
    "\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_loss = sum(val_losses) / sum(val_nums)\n",
    "    score = mcrmse(cfg, val_preds, valid_df)\n",
    "\n",
    "    val_log = {\n",
    "        'val_loss': val_loss,\n",
    "        'mcrmse': score\n",
    "    }\n",
    "    display(val_log)\n",
    "\n",
    "    if best_val_score > score:\n",
    "        print('\\033[31m'+'save model weight'+'\\033[0m')\n",
    "        best_val_preds = val_preds\n",
    "        best_val_score = score\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n",
    "        )\n",
    "    \n",
    "    return best_val_preds, best_val_score\n",
    "\n",
    "def training(cfg, train):\n",
    "    # =====================\n",
    "    # Training\n",
    "    # =====================\n",
    "    set_seed(cfg.seed)\n",
    "    oof_pred = np.zeros((len(train), 6), dtype=np.float32)\n",
    "    fold_score = []\n",
    "\n",
    "    for fold in cfg.trn_fold:\n",
    "        print(f'==========fold {fold}==========')\n",
    "        if (fold <= 5):\n",
    "            valid_df = train.loc[cfg.folds==fold]\n",
    "            valid_idx = list(valid_df.index)\n",
    "            best_val_preds = np.load(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'))\n",
    "            oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n",
    "            \n",
    "        else:\n",
    "            # dataset, dataloader\n",
    "            train_df = train.loc[cfg.folds!=fold]\n",
    "            valid_df = train.loc[cfg.folds==fold]\n",
    "            train_idx = list(train_df.index)\n",
    "            valid_idx = list(valid_df.index)\n",
    "\n",
    "            # Datasetの設定\n",
    "            train_dataset = TrainDataset(cfg, train_df)\n",
    "            valid_dataset = TrainDataset(cfg, valid_df)\n",
    "            train_loader = DataLoader(\n",
    "                dataset=train_dataset, \n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=True,\n",
    "                pin_memory=True,\n",
    "                drop_last=True,\n",
    "            )\n",
    "            valid_loader = DataLoader(\n",
    "                dataset=valid_dataset,\n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=False,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "            )\n",
    "\n",
    "            # model\n",
    "            model = CustomModel(cfg)\n",
    "            torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n",
    "            model = reinit_bert(model)\n",
    "            # model = replace_mixout(model)\n",
    "            model = model.to(cfg.device)\n",
    "\n",
    "            # optimizer, scheduler\n",
    "            optimizer_grouped_parameters = get_optimizer_params(model,\n",
    "                                                    encoder_lr=cfg.encoder_lr, \n",
    "                                                    decoder_lr=cfg.decoder_lr,\n",
    "                                                    hidden_weight_lr = cfg.hidden_weight_lr,\n",
    "                                                    layer_wise_decay = cfg.layer_wise_decay,\n",
    "                                                    weight_decay=cfg.weight_decay)\n",
    "            optimizer = AdamW(optimizer_grouped_parameters, lr=cfg.encoder_lr, eps=cfg.eps, betas=cfg.betas, weight_decay=cfg.weight_decay)\n",
    "\n",
    "            num_train_steps = int(len(train_df) / cfg.batch_size * cfg.n_epochs)\n",
    "            scheduler = get_scheduler(cfg, optimizer, num_train_steps)\n",
    "\n",
    "            # AWP\n",
    "            awp = AWP(\n",
    "                cfg,\n",
    "                model,\n",
    "                optimizer,\n",
    "                adv_lr=cfg.awp_lr, \n",
    "                adv_eps=cfg.awp_eps\n",
    "            )\n",
    "\n",
    "            # model-training\n",
    "            best_val_preds = None\n",
    "            best_val_score = 9999\n",
    "\n",
    "            for epoch in range(cfg.n_epochs):\n",
    "                # training\n",
    "                print(f\"# ============ start epoch:{epoch} ============== #\")\n",
    "                train_losses = []\n",
    "                train_nums = []\n",
    "                model.train() \n",
    "                scaler = GradScaler(enabled=cfg.apex)\n",
    "                with tqdm(train_loader, total=len(train_loader)) as pbar:\n",
    "                    for step, (inputs, labels) in enumerate(pbar):\n",
    "                        inputs = collate(inputs)\n",
    "                        for k, v in inputs.items():\n",
    "                            inputs[k] = v.to(cfg.device)\n",
    "                        labels = labels.to(cfg.device)\n",
    "                        with autocast(enabled = cfg.apex):\n",
    "                            loss, output = model(inputs, labels)\n",
    "\n",
    "                        pbar.set_postfix({\n",
    "                            'loss': loss.item(),\n",
    "                            'lr': scheduler.get_lr()[0]\n",
    "                        })\n",
    "                        train_losses.append(loss.item() * len(labels))\n",
    "                        train_nums.append(len(labels))\n",
    "\n",
    "                        if cfg.gradient_accumulation_steps > 1:\n",
    "                            loss = loss / cfg.gradient_accumulation_steps\n",
    "\n",
    "                        scaler.scale(loss).backward()\n",
    "\n",
    "                        if cfg.clip_grad_norm is not None:\n",
    "                            # scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(\n",
    "                                model.parameters(),\n",
    "                                cfg.clip_grad_norm\n",
    "                            )\n",
    "\n",
    "                        # AWP\n",
    "                        if cfg.awp_start <= epoch:\n",
    "                            loss = awp.attack_backward(inputs, labels)\n",
    "                            scaler.scale(loss).backward()\n",
    "                            awp._restore()\n",
    "\n",
    "                        if (step+1) % cfg.gradient_accumulation_steps == 0:\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            optimizer.zero_grad()\n",
    "                            scheduler.step()\n",
    "\n",
    "                        if step % cfg.eval_step == 0 and step != 0:\n",
    "                            print(f'fold: {fold}, epoch: {epoch}, step: {step}')\n",
    "                            best_val_preds, best_val_score = evaluating(\n",
    "                                cfg, valid_loader,\n",
    "                                model,\n",
    "                                valid_df,\n",
    "                                fold,\n",
    "                                best_val_preds,\n",
    "                                best_val_score,\n",
    "                            )\n",
    "                            model.train()\n",
    "\n",
    "                train_loss = sum(train_losses)/sum(train_nums)\n",
    "                train_log = {\n",
    "                    'train_loss':train_loss\n",
    "                }\n",
    "                display(train_log)\n",
    "\n",
    "                # evaluating(epoch)\n",
    "                print(f'fold: {fold}, epoch: {epoch}, complete')\n",
    "                best_val_preds, best_val_score = evaluating(\n",
    "                    cfg, valid_loader,\n",
    "                    model,\n",
    "                    valid_df,\n",
    "                    fold,\n",
    "                    best_val_preds,\n",
    "                    best_val_score,\n",
    "                )\n",
    "\n",
    "            oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n",
    "            np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n",
    "            fold_score.append(best_val_score)\n",
    "            del model; gc.collect()\n",
    "\n",
    "    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n",
    "\n",
    "    # =====================\n",
    "    # scoring\n",
    "    # =====================\n",
    "    score = mcrmse(cfg, oof_pred, train)\n",
    "    print('fold score：', fold_score)\n",
    "    print('CV:', round(score, 4))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f97fff63a18740a1b3f54da3e6e934e2",
      "1ecc5a635a6d40cd80e1d7d5fb94855f",
      "e82c6cbf01d343bab7d92748491869f4",
      "dac20cb374ec4aa899abfd3a16c65f2c",
      "6c0ec69f78d0423ea90ff694fe055bf5",
      "590be7567dc24a288231bcdcc6990083",
      "c452697f3d49438f9209aad3b1421a26",
      "a48058e83abd4f718fae8f75782b14ba",
      "30572b0eb9bd41438288f7136edb2ed1",
      "8c90bee7a2564dc492ae05b67b9b3556",
      "6050f14fc2fe424baf58f1b99b31bf3c",
      "a1ca05a89d4b4538af02c8a28a76b693",
      "8ed1982dc5e44f89b63be47b53fb582a",
      "3f4185417cc74a0d95d878dd8acb77d6",
      "9138177cc8444dd091f4b3cc8feb5f4d",
      "dc466ca35ec94bb1a48dc7266a973cbe",
      "b16926958b5e4c1ba95c8af782d701dc",
      "7f0a323be2ab45b29a0bca3797476a6c",
      "500c33f80990430783f7335fbd778406",
      "58a1269d80c74f9eaacd4e72cf863b86",
      "433c26b0eb12423c8734cd599bde614c",
      "905045c3525b40a2b1081298e79db649",
      "69aa466f09964e39b5eac01526c23b8b",
      "21fe890718f246ebbd186c8b44737774",
      "e755cc3cedcf4ebd897701171d17f00d",
      "ab0f9c50d4f54f0abd40d88ab738cb1a",
      "2eb243bccbe14df3aea49ac1bb7115e7",
      "1a0f67656f1f4186bee6d24cf53d5557",
      "2b3c21f294a742ed962228a0bfaae499",
      "9716ad8dcaf548ccb4e0275c338940f6",
      "fb38fbbe8ea64f1e82378966279ef7a3",
      "7b7c465f06d449bb9c53792c255fdf80",
      "dbce5d80f3cd4e3a9c5954996584da2b",
      "7701b4c2f40e47449edf603bce59ab18",
      "56119573e047417a88c5646be9811205",
      "b8690bf0beda4c30a575a7da743bbc95",
      "97233fab075b4c5098291260b374ac8f",
      "f4948de16e874854bc2bba6e5c4eec3a",
      "2cc46a493a96438a883ccf8b4c56e52b",
      "dc4db4363b2e4fcfa836de8d835cd187",
      "bcb3508788f747baa9854778dfa1d17b",
      "da3e3df75eaf4ea68f781bef9676580d",
      "cfbd997bf4f44c628daf392560fb7d42",
      "7c3b79dc32a04675847b90647b1645b8",
      "160bb77bf7d046c8830264297b76e73c",
      "a616efe19edd4f08adbd7b2cf67e50d9",
      "b1f4d50d41664406974feafb8758661e",
      "57543b2f69d045eda6ec6f0ab2ca7a22",
      "595727649d8e4fb9961bb0f2b075f02a",
      "dc19d93dfc0f4fc58382396459b6ee67",
      "1deeaf00703d4853bacc3959e3a9743f",
      "bd6d283cc88f4a08b4788726dd21b673",
      "1cece10d542c4b1a8952d1f0c8dc8701",
      "860bf802bc1341e8b598b1ae048672b9",
      "8336554bb42a47abbc69a0b96985da71",
      "07a146ce17814ef18e57c1689e80b7a5",
      "f57e99e43abd4648bd92acd3e7bce70a",
      "1545817f66224b489dbdd29298322fc4",
      "244cfb28ad44462399b989654ee73f1d",
      "3b64a0b2df794a08b4da12a57bdf2c9e",
      "c13a8188aacc4b6fbf1e7ee4995e8cad",
      "e3558aa363f544bb9428e322d38e1579",
      "caf2df211e6d42f6aaf388e663a9101f",
      "572de2d0acc448b9b3190eff69ce467b",
      "cb285836824144868d5dee19e9120c18",
      "b4848c1be3404e819eda26cc9f68f8ca",
      "242f2f48f831423d9c34a7e0e0a1f783",
      "4fcd8106b386440699c4c2668113ee06",
      "ec28e786c0f54e3dbe039138fd2dbec0",
      "46cd92da1eaf467fbc4195a5a5d4dfda",
      "8652103787a241a4877b14331e37977d",
      "c337fc2ee3b140569380774073e55d1f",
      "09e8d0f15a304725b693e95671ca4d22",
      "9bc74699771041a083008cf4aaa54427",
      "6399d313fb8e4c3c9d01f372a8f2f8fd",
      "8a3d8a7355a745059a6a2ddfcc499fb7",
      "6607963a0fa541ffb7b23854949fadf4",
      "b0b0664304bd4c53a7837f11152ae129",
      "b2def3fe25074b028dfa71e9a93e1f78",
      "9e0480a09b4141449c3d1e44370be7c2",
      "6d654a5123f949db952f8073124a36aa",
      "774064f73a2a4109b46750cbc571254c",
      "272fe1ebd3694127affead4d323c8295",
      "9248971857ac48be9ae64a2c629d0ef9",
      "32e4aeb07e064b61a2da53fc3bf4f0ba",
      "46260f123eef494392afd073e66b8091",
      "8b2519f767d2495a8e335322ab2a7535",
      "e9bebd0b46f445c8b8d99b96a83de8fb",
      "121efff387394860836d9761849f1237",
      "c4e1be41fd564daab22f5ba041b994be",
      "c1b659fca37e45ff8d8b6a8b9ee33585",
      "05d0de7dfea94efba9d683f1d2fa8f08",
      "1e7d9093b07b43eb9b27a1ac41acb901",
      "52591471de5446efbb20615063ee9230",
      "1eeb5824efa047eeb5f2bac506bc6d59",
      "007bc88afc044fd181a33b9493907124",
      "dde544bb15554df8a5e0a87266c52c3e",
      "78634bb7c2ad451e9562424e753306e5",
      "c82b185269cd4d9d968912350370306f",
      "f5a82127eb9a46fe9e0365d27e7dd4ec",
      "24806783384047d58761f73f4d2d8ea9",
      "d66d23e7a177445caed34ee798db3f34",
      "9df7e90b9ff34e849bf5ca5ad9979dd8",
      "b0bf452f7bde4ef88bc1287d4ee834ae",
      "32a0284f3cf448248a2537e7567e597d",
      "96a12915e53b40f98861ff2bd9d8a4ad",
      "477e9a4b93be4305b6fc6bf6769b9d4c",
      "aa435d2f8d7d44fda282d7014df76628",
      "e76298e3bbbe4c3ea1de335653042331",
      "0d2d18217dc74f89bed0fc7db8d118a8",
      "dcd58a97eb8948dea25d7acf0508d337",
      "89104a1fc56442b3a610e8d57f20ee38",
      "640a5224401647d99f53205d877fdf4b",
      "9285870d957a42d5a3902bc922f88deb",
      "9fa7a7b25ab34cf099f38e5d5241ef17",
      "067d44b36d04460680a67af898c5763e",
      "a88c7bf8581940328e05152ffdde25ab",
      "7aa779cdef3541f3a08b903781f0a941",
      "c49fc2c55eaf4f00a54c339161df7f48",
      "dab8c38e93a54ace8ae2b5625c94eb1d",
      "ec0334dc099140db9f1df2dad6b37d25",
      "cb86c0a2fcc5419e9e2b1bc08c62f71f",
      "8e47cdfac9b3496cb4344ffa535dc197",
      "be3b1c91d65e4c4794e507cdfe488262",
      "f90316af55664792a2af4772f6297c02",
      "6f0f2bec563f47b591c6183cdfa01aec",
      "bde92a0baf094398bcba4c51f171a54a",
      "1ddd144b0e334ae1ad53541f2822f778",
      "08a124c55224402dafd6b040b0100ce2",
      "51f6c6a68d0e4f339bc3a55bf9753fde",
      "69d0ae1786634042ae6006281736faad",
      "96340b4ef2d74042a5093d4ca2f83ff5",
      "f36df875720d4482922e2161532be764",
      "00423a15cfa0402e94fa0712bcd6847d",
      "473cef375cbe4f578f39c8f7de15a73e",
      "d7c8117b7abb4563b1fa3b5a0660a785",
      "d1828cccf559451c931eb91b8143eed8",
      "c1f3140bdce04e68903b62521528455b",
      "a9137784d48a41318c102ce6f0f10ac2",
      "651852ebd64b410dbec6657c3d490bb1",
      "dd1aa8cb6e374370bc7e47aaaccd9831",
      "8eb43b3976cf44b0a72ff39a5af7fe6b",
      "f8e7b0947f7c41a79ce160823bee8d9b",
      "27f073e41d674201afcb2c23f0d5df0b",
      "84a06b67a8af4dd3a2d842379ccedafd",
      "ecfd863a1da64573aa05c5861516ede6",
      "39d20673d7c04015992813563c30e4fd",
      "ccefc54b9931476faeac482e526a232c",
      "81b5030031b14541aa26093e2d186a05",
      "78768e4014554c22a1108422c6cee8a1",
      "0286d14a0346423ab3fe39671321cf50",
      "3cefd3d4d6d44332984c86c0cad427ee",
      "07de61912bb04fb5907d4815ee6a7ea3",
      "ae3b121b788d4fb3a00550f157a60fb6",
      "1f5240fb57424edbab3ce4c1b861b974",
      "3b3a144838f348858c194bf06065632b",
      "2091c9a6fe7c4a0c83a50b5834dfb77b",
      "21872ec47d514892bb4c6d61f3477c75",
      "d32aa364af3c4aaa838de14b74eaa821",
      "487a9766368e4454b04a3e6e89897000",
      "52f390a6088f4b5c967357c7f59920c7",
      "ad98c5e5e332481ebe61f642ce6c47f8",
      "323a150c3774411db4d5e5e8eabee899",
      "962b7006629d449da55a2bdb4b241341",
      "46f6d458a6224d749672b5bd1c8b0f0c",
      "48cc97383fda45e3935643c687dc78e7",
      "950b43bc46234aa18221a8e919633eb6",
      "0e69653e4f494e2d80569a633339c156",
      "895ee0c28b19459195823031bd16521a",
      "14135c4ce258436ca0baff20cbadbecf"
     ]
    },
    "id": "gSrrvDWVpxN_",
    "outputId": "6837f7b2-7e24-452e-f014-7f2872136f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.16.2\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (1.23.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (2022.7.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.16.2) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.16.2) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->transformers==4.16.2) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.16.2) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.16.2) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.16.2) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.16.2) (2.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers==4.16.2) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.16.2) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==4.16.2) (1.1.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895242 sha256=e400f1b74abdea782cf49f24fb0969d656696fec9bd8f8af464185d46c6532dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.20.1\n",
      "    Uninstalling transformers-4.20.1:\n",
      "      Successfully uninstalled transformers-4.20.1\n",
      "Successfully installed sacremoses-0.0.53 transformers-4.16.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tokenizers==0.11.6\n",
      "  Downloading tokenizers-0.11.6-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "Successfully installed tokenizers-0.11.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.9/dist-packages (4.16.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (1.23.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (0.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (4.64.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (21.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (3.19.4)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.9/dist-packages (from transformers[sentencepiece]) (0.1.96)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[sentencepiece]) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers[sentencepiece]) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[sentencepiece]) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers[sentencepiece]) (2019.11.28)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers[sentencepiece]) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers[sentencepiece]) (8.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0menv: TOKENIZERS_PARALLELISM=true\n",
      "tokenizers.__version__: 0.11.6\n",
      "transformers.__version__: 4.16.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b642d5a668a47b4a878f2de4331c9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b67ec1312974607a9ad43f8ee9a5c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4904c82a62a94d188b65cfcbeac09feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========fold 0==========\n",
      "==========fold 1==========\n",
      "==========fold 2==========\n",
      "==========fold 3==========\n",
      "==========fold 4==========\n",
      "==========fold 5==========\n",
      "==========fold 6==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d048d5669e6441a193590c46e14af76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:0 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfd17dc9b9747b682d222cc810561d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 0, step: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586320ee811441a298c6614de270aaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.22733455073193212, 'mcrmse': 0.6829540467772189}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 0, step: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f26aaa3be84dfba21f8c33bc864cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.16022198790174616, 'mcrmse': 0.5700369433775405}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 0, step: 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6cec0b65384f9b9ccf6f58c9a98743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.13549373144536372, 'mcrmse': 0.5237638518948373}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 0, step: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a347274cdd4c84919a08ec42f9348c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11782084874179967, 'mcrmse': 0.48738668059737933}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 0, step: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c14ac3dc6bf47029a6b1ca85cde989d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1185259457553744, 'mcrmse': 0.4887038625408886}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.41920032924549144}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 0, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e2cfef271e4b65a30cee26cd8954de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11916942661985412, 'mcrmse': 0.4901162631707279}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:1 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f251b4eeb5f4150b0f7ba91a0260140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 1, step: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f476a00e0f9d46e0a2ad2b1f70abd819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11272363867753607, 'mcrmse': 0.47625986595986425}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 1, step: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6de705eee64c84925c418c7c5f2250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11845632785421503, 'mcrmse': 0.4884113859537327}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 1, step: 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e1f5a463e6433c93948fbc40989c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11388071837937436, 'mcrmse': 0.4791243379148108}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 1, step: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2882192a4caa41b5aaa65f4a688cf2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1209542845444911, 'mcrmse': 0.492819262737255}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 1, step: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad885d62da24504aaa7d87003d1331e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11463855839598819, 'mcrmse': 0.4796604804532148}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.10539841198108413}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 1, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea6a223890b4aa89eec96140f452f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1155449177336205, 'mcrmse': 0.4821168673158465}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:2 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4518a341c3d54560af11e6b5f9b1c182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 2, step: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d944e3ed90cc4ae0b8794fde8f21149f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11657021903549619, 'mcrmse': 0.4845369496823427}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 2, step: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5597bce1524e52aeba2509193716d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.111780415524912, 'mcrmse': 0.47442078787865766}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 2, step: 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f775601cd7416d9479e12c3c3349f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11593051468167463, 'mcrmse': 0.482963102007669}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 2, step: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8466d20b76d547d497abc6a1b1f77bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1107502951265296, 'mcrmse': 0.47194130456217204}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 2, step: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5934fda65b41dfa0b06ba05fdda7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11617227013001356, 'mcrmse': 0.4828206656005195}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.09470033881000497}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 2, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b28922b3e545eabed0c33dabd35fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10855049624696107, 'mcrmse': 0.4670903551473774}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "# ============ start epoch:3 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebde65ae11f4afdaac8a70220f7f6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 3, step: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dc5af901a248f98c2ebf21433711a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11375553763049948, 'mcrmse': 0.47880677163275764}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 3, step: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e6fb125e944f94b534aaeb2393e690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11128108273915317, 'mcrmse': 0.4733227497552939}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 3, step: 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6312e234ae4031a58be8c583cccfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10867050703605423, 'mcrmse': 0.46727643575770444}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 3, step: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31007fd4545345fc8310fc42ffff0928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10844590099495086, 'mcrmse': 0.46700998268898675}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 3, step: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bef88f8c965406f8b1a322a368b7aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11024904258720711, 'mcrmse': 0.47114565176046364}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.08480533339421857}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 3, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9bba16c6754ef2a2341f12a0f19b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10875930088331633, 'mcrmse': 0.46773990577180236}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:4 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e9a52179c54635aa7ac53be0445827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 4, step: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a405ec254dcf4a14af2ce021563121c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10962266128157716, 'mcrmse': 0.46971799672950326}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 4, step: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559c7b5a91e8491aaa54dc5997a4b6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10857024581154899, 'mcrmse': 0.4673687024030405}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 4, step: 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84a714da5094ac6a1cf81a2c61fde11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10892677366200006, 'mcrmse': 0.46817016140821077}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 4, step: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578c7d68907a410cace862be98aa34c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10840396177204674, 'mcrmse': 0.46700939912791045}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 6, epoch: 4, step: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ecd8374099483aa2053a9c08b7afa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1083226378845132, 'mcrmse': 0.4668249965877975}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.07871000924232331}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 6, epoch: 4, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0cbc081aa447b49a33160153d1f5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10833150752441352, 'mcrmse': 0.4668445779033584}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========fold 7==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:0 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e8e6480a6b4c30a84d5f8f66329451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7, epoch: 0, step: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69a539e03ed4622a2df494cb053e453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.2564957813381234, 'mcrmse': 0.7300074697824839}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 7, epoch: 0, step: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8009bb6517e44a6fbc4d9459a24abf82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1333218097038891, 'mcrmse': 0.5176057564734732}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 7, epoch: 0, step: 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d3be267f27420aa30f41367bb7387a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11622278640032424, 'mcrmse': 0.4835966395631997}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 7, epoch: 0, step: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9355a88c25d748faa2b043806f047fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1048863895256501, 'mcrmse': 0.45891262162599783}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 7, epoch: 0, step: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1296388b78254d4aaa1540f92183e6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11375138512276628, 'mcrmse': 0.4770173496282191}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.39778721837157555}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7, epoch: 0, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27436a2895264901a88580a302c78266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10590182976497103, 'mcrmse': 0.4611306943041254}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ============ start epoch:1 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569420b8744b4bb08b86c661aa23cdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7, epoch: 1, step: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5775130cee98466088f6b44c6cea3c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.1056201643955982, 'mcrmse': 0.4594850925072491}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7, epoch: 1, step: 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d225602c49478e9f3f440634e381e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.11378213195392238, 'mcrmse': 0.4789003129227877}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7, epoch: 1, step: 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf92a969006247cda5fe5813214b2ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10841104249134088, 'mcrmse': 0.4657996619625369}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7, epoch: 1, step: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c36768ee7694539b5e59bf545b2880a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10346065415903126, 'mcrmse': 0.4552374708497679}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "fold: 7, epoch: 1, step: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8406e5f02b4b178ce85025852c3b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.10224550928148772, 'mcrmse': 0.45246728797606456}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.10707814327695153}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 7, epoch: 1, complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903d81a9a5884ef3a4a42a45ee3acd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.09998751955721384, 'mcrmse': 0.44784114339220016}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msave model weight\u001b[0m\n",
      "# ============ start epoch:2 ============== #\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f745685043264ab2ab9077eae54b7050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================\n",
    "# Main\n",
    "# =====================\n",
    "\n",
    "# setup\n",
    "cfg = setup(Config)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import tokenizers\n",
    "import sentencepiece\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "\n",
    "# main\n",
    "train = pd.read_csv(os.path.join(cfg.INPUT, 'train.csv'))\n",
    "\n",
    "train = processing_features(train)\n",
    "\n",
    "cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n",
    "cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n",
    "cfg.folds = get_multilabelstratifiedkfold(train, cfg.target_list, cfg.num_fold, cfg.seed)\n",
    "cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n",
    "score = training(cfg, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PwTIVNWuwErN"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ecc5a635a6d40cd80e1d7d5fb94855f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_590be7567dc24a288231bcdcc6990083",
      "placeholder": "​",
      "style": "IPY_MODEL_c452697f3d49438f9209aad3b1421a26",
      "value": " 20%"
     }
    },
    "30572b0eb9bd41438288f7136edb2ed1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f4185417cc74a0d95d878dd8acb77d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_500c33f80990430783f7335fbd778406",
      "max": 98,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_58a1269d80c74f9eaacd4e72cf863b86",
      "value": 98
     }
    },
    "433c26b0eb12423c8734cd599bde614c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "500c33f80990430783f7335fbd778406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58a1269d80c74f9eaacd4e72cf863b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "590be7567dc24a288231bcdcc6990083": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6050f14fc2fe424baf58f1b99b31bf3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c0ec69f78d0423ea90ff694fe055bf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f0a323be2ab45b29a0bca3797476a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c90bee7a2564dc492ae05b67b9b3556": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ed1982dc5e44f89b63be47b53fb582a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b16926958b5e4c1ba95c8af782d701dc",
      "placeholder": "​",
      "style": "IPY_MODEL_7f0a323be2ab45b29a0bca3797476a6c",
      "value": "100%"
     }
    },
    "905045c3525b40a2b1081298e79db649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9138177cc8444dd091f4b3cc8feb5f4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_433c26b0eb12423c8734cd599bde614c",
      "placeholder": "​",
      "style": "IPY_MODEL_905045c3525b40a2b1081298e79db649",
      "value": " 98/98 [00:33&lt;00:00,  3.71it/s, val_loss=0.233]"
     }
    },
    "a1ca05a89d4b4538af02c8a28a76b693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ed1982dc5e44f89b63be47b53fb582a",
       "IPY_MODEL_3f4185417cc74a0d95d878dd8acb77d6",
       "IPY_MODEL_9138177cc8444dd091f4b3cc8feb5f4d"
      ],
      "layout": "IPY_MODEL_dc466ca35ec94bb1a48dc7266a973cbe"
     }
    },
    "a48058e83abd4f718fae8f75782b14ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b16926958b5e4c1ba95c8af782d701dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c452697f3d49438f9209aad3b1421a26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dac20cb374ec4aa899abfd3a16c65f2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c90bee7a2564dc492ae05b67b9b3556",
      "placeholder": "​",
      "style": "IPY_MODEL_6050f14fc2fe424baf58f1b99b31bf3c",
      "value": " 80/391 [03:53&lt;15:31,  2.99s/it, loss=0.302, lr=4.1e-6]"
     }
    },
    "dc466ca35ec94bb1a48dc7266a973cbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e82c6cbf01d343bab7d92748491869f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a48058e83abd4f718fae8f75782b14ba",
      "max": 391,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30572b0eb9bd41438288f7136edb2ed1",
      "value": 80
     }
    },
    "f97fff63a18740a1b3f54da3e6e934e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ecc5a635a6d40cd80e1d7d5fb94855f",
       "IPY_MODEL_e82c6cbf01d343bab7d92748491869f4",
       "IPY_MODEL_dac20cb374ec4aa899abfd3a16c65f2c"
      ],
      "layout": "IPY_MODEL_6c0ec69f78d0423ea90ff694fe055bf5"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
